{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import math\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"oracle://{user}:{pw}@145.33.225.194/{db}\"\n",
    "                       .format(user=\"football_select\",\n",
    "                               pw=\"datashare\",\n",
    "                               db=\"orcl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Get_aggregated_data(parameter_code,num_bin):\n",
    "      \n",
    "    \n",
    "    #ball,keeper and referree are excluded\n",
    "    sql=\"select BIN\\\n",
    "         ,      PARAMETER_CODE\\\n",
    "         ,      HALF_INDICATOR\\\n",
    "        ,avg(AVG_VLIR) dist_vlir\\\n",
    "        ,avg(PERC_VLIR) perc_vlir\\\n",
    "        ,avg(AVG_LIR)  dist_lir\\\n",
    "        ,avg(PERC_LIR) perc_lir\\\n",
    "        ,avg(AVG_MIR) dist_mir\\\n",
    "        ,avg(PERC_MIR) perc_mir\\\n",
    "        ,avg(AVG_HIR) dist_hir\\\n",
    "        ,avg(PERC_HIR) perc_hir\\\n",
    "        ,avg(AVG_VHIR) dist_vhir\\\n",
    "        ,avg(PERC_VHIR) perc_vhir\\\n",
    "        ,avg(TOTAL_AVG_DISTANCE) total_avg_distance\\\n",
    "         from lit_perc_dist_in_speedzone_game_v\\\n",
    "         where parameter_code like :parameter_code\\\n",
    "         and bin <= :num_bin\\\n",
    "         group by half_indicator,bin,player_id,game_id, parameter_code\\\n",
    "         order by half_indicator,bin asc\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'parameter_code' :parameter_code,'num_bin' : num_bin}, con=engine)\n",
    "    return df\n",
    "\n",
    "#can be added:\n",
    "#,      FULL_BIN_IND\\\n",
    "#,      FULL_GAME_IND\\\n",
    "#,      CLUB_ID\\\n",
    "#,      GAME_ID\\\n",
    "#,      PLAYER_ID\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Get_aggregated_data_sub(parameter_code,num_bin):\n",
    "      \n",
    "    \n",
    "    #ball,keeper and referree are excluded\n",
    "    sql=\"select BIN\\\n",
    "         ,      PARAMETER_CODE\\\n",
    "         ,      HALF_INDICATOR\\\n",
    "        ,avg(AVG_VLIR) dist_vlir\\\n",
    "        ,avg(PERC_VLIR) perc_vlir\\\n",
    "        ,avg(AVG_LIR) dist_lir\\\n",
    "        ,avg(PERC_LIR) perc_lir\\\n",
    "        ,avg(AVG_MIR) dist_mir\\\n",
    "        ,avg(PERC_MIR) perc_mir\\\n",
    "        ,avg(AVG_HIR) dist_hir\\\n",
    "        ,avg(PERC_HIR) perc_hir\\\n",
    "        ,avg(AVG_VHIR) dist_vhir\\\n",
    "        ,avg(PERC_VHIR) perc_vhir\\\n",
    "        ,avg(TOTAL_AVG_DISTANCE) total_avg_distance\\\n",
    "         from lit_perc_dist_in_speedzone_game_sub_v\\\n",
    "         where parameter_code like :parameter_code\\\n",
    "         and bin <= :num_bin\\\n",
    "         group by half_indicator,bin,player_id,game_id, parameter_code\\\n",
    "         order by half_indicator,bin asc\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'parameter_code' :parameter_code,'num_bin' : num_bin}, con=engine)\n",
    "    return df\n",
    "\n",
    "#can be added:\n",
    "#,      FULL_BIN_IND\\\n",
    "#,      FULL_GAME_IND\\\n",
    "#,      CLUB_ID\\\n",
    "#,      GAME_ID\\\n",
    "#,      PLAYER_ID\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_visualize_data(parameter_code,num_bin):\n",
    "      \n",
    "    \n",
    "    #ball,keeper and referree are excluded in the view\n",
    "    sql=\"select BIN\\\n",
    "         ,      PARAMETER_CODE\\\n",
    "         ,      HALF_INDICATOR\\\n",
    "         ,avg(AVG_VLIR) dist_vlir\\\n",
    "        ,avg(PERC_VLIR) perc_vlir\\\n",
    "        ,avg(AVG_LIR) dist_lir\\\n",
    "        ,avg(PERC_LIR) perc_lir\\\n",
    "        ,avg(AVG_MIR) dist_mir\\\n",
    "        ,avg(PERC_MIR) perc_mir\\\n",
    "        ,avg(AVG_HIR) dist_hir\\\n",
    "        ,avg(PERC_HIR) perc_hir\\\n",
    "        ,avg(AVG_VHIR) dist_vhir\\\n",
    "        ,avg(PERC_VHIR) perc_vhir\\\n",
    "        ,avg(TOTAL_AVG_DISTANCE)total_avg_distance\\\n",
    "         from LIT_VISUALIZE_DIST_IN_SPEEDZONE_GAME_V\\\n",
    "         where parameter_code like :parameter_code\\\n",
    "         and bin <= :num_bin\\\n",
    "         group by half_indicator,bin,parameter_code\\\n",
    "         order by half_indicator,bin asc\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'parameter_code' :parameter_code,'num_bin' : num_bin}, con=engine)\n",
    "    return df\n",
    "\n",
    "#can be added:\n",
    "#,      FULL_BIN_IND\\\n",
    "#,      FULL_GAME_IND\\\n",
    "#,      CLUB_ID\\\n",
    "#,      GAME_ID\\\n",
    "#,      PLAYER_ID\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_visualize_data_sub(parameter_code,num_bin):\n",
    "      \n",
    "    \n",
    "    #ball,keeper and referree are excluded\n",
    "    sql=\"select BIN\\\n",
    "         ,      PARAMETER_CODE\\\n",
    "         ,      HALF_INDICATOR\\\n",
    "         ,avg(AVG_VLIR) dist_vlir\\\n",
    "        ,avg(PERC_VLIR) perc_vlir\\\n",
    "        ,avg(AVG_LIR) dist_lir\\\n",
    "        ,avg(PERC_LIR) perc_lir\\\n",
    "        ,avg(AVG_MIR) dist_mir\\\n",
    "        ,avg(PERC_MIR) perc_mir\\\n",
    "        ,avg(AVG_HIR) dist_hir\\\n",
    "        ,avg(PERC_HIR) perc_hir\\\n",
    "        ,avg(AVG_VHIR) dist_vhir\\\n",
    "        ,avg(PERC_VHIR) perc_vhir\\\n",
    "        ,avg(TOTAL_AVG_DISTANCE)total_avg_distance\\\n",
    "         from LIT_VISUALIZE_DIST_IN_SPEEDZONE_GAME_SUB_V\\\n",
    "         where parameter_code like :parameter_code\\\n",
    "         and bin <= :num_bin\\\n",
    "         group by half_indicator,bin,parameter_code\\\n",
    "         order by half_indicator,bin asc\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'parameter_code' :parameter_code,'num_bin' : num_bin}, con=engine)\n",
    "    return df\n",
    "\n",
    "#can be added:\n",
    "#,      FULL_BIN_IND\\\n",
    "#,      FULL_GAME_IND\\\n",
    "#,      CLUB_ID\\\n",
    "#,      GAME_ID\\\n",
    "#,      PLAYER_ID\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_distance_speedzone():\n",
    "    sql = \"select  vlir\\\n",
    "           , perc_vlir\\\n",
    "           , lir\\\n",
    "           , perc_lir\\\n",
    "           ,   mir\\\n",
    "           , perc_mir\\\n",
    "           , hir\\\n",
    "           , perc_hir\\\n",
    "           ,   vhir\\\n",
    "           , perc_vhir\\\n",
    "           ,     game_id\\\n",
    "           from whole_game_speedzone_v\"\n",
    "    df = pd.read_sql(sql,con=engine)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_distance_half_speedzone():\n",
    "    sql = \"select vlir\\\n",
    "           , perc_vlir\\\n",
    "           , lir\\\n",
    "           , perc_lir\\\n",
    "           ,   mir\\\n",
    "           , perc_mir\\\n",
    "           , hir\\\n",
    "           , perc_hir\\\n",
    "           ,   vhir\\\n",
    "           , perc_vhir\\\n",
    "           , half_indicator\\\n",
    "           ,     game_id\\\n",
    "           from lit_half_game_speedzone_v\"\n",
    "    df = pd.read_sql(sql,con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_distance_half_sub_speedzone():\n",
    "    sql = \"select vlir\\\n",
    "           , perc_vlir\\\n",
    "           , lir\\\n",
    "           , perc_lir\\\n",
    "           ,   mir\\\n",
    "           , perc_mir\\\n",
    "           , hir\\\n",
    "           , perc_hir\\\n",
    "           ,   vhir\\\n",
    "           , perc_vhir\\\n",
    "           , half_indicator\\\n",
    "           ,     game_id\\\n",
    "           from lit_half_game_speedzone_sub_v\"\n",
    "    df = pd.read_sql(sql,con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distance in speed zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create speedzone dataframes average of all games \n",
    "#df_1M = Get_aggregated_data('1M',45)\n",
    "df_5M = Get_visualize_data('5M',9)\n",
    "df_15M = Get_visualize_data('15M',3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create speedzone dataframes average of all games of the substitutes\n",
    "df_5M_sub = Get_visualize_data_sub('5M',9)\n",
    "df_15M_sub = Get_visualize_data_sub('15M',3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create summarized data\n",
    "#df_5M.to_csv('lit_5M_speedzone_avg_total_game_new.csv')\n",
    "#df_1M.to_csv('1M_speedzone_total_game.csv')\n",
    "#df_15M.to_csv('lit_15M_speedzone_total_game_new.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create summarized data substitutes\n",
    "#df_5M_sub.to_csv('lit_5M_speedzone_avg_substitutes.csv')\n",
    "#df_1M.to_csv('1M_speedzone_total_game.csv')\n",
    "#df_15M_sub.to_csv('lit_15M_speedzone_avg_substitutes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "#df_5M = pd.read_csv('5M_speedzone_avg_total_game_new.csv',)\n",
    "#df_15M = pd.read_csv('15M_speedzone_total_game_new.csv')\n",
    "#df_5M_sub = pd.read_csv('5M_speedzone_avg_substitutes.csv',)\n",
    "#df_15M_sub = pd.read_csv('15M_speedzone_avg_substitutes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full game dataframes for percentage \n",
    "df_5M_perc = df_5M.drop(['parameter_code', 'dist_vlir','dist_lir',\\\n",
    "                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)\n",
    "#df_1M_perc = df_1M.drop(['parameter_code', 'avg_lessthan5','avg_between5and10',\\\n",
    "                       #'avg_between10and15','avg_between15and20','avg_between20and25','avg_between25and30','avg_morethan30',\\\n",
    "                       #'total_avg_distance'], axis = 1)\n",
    "df_15M_perc = df_15M.drop(['parameter_code',  'dist_vlir','dist_lir',\\\n",
    "                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create substitute dataframes for percentage \n",
    "df_5M_perc_sub = df_5M_sub.drop(['parameter_code', 'dist_vlir','dist_lir',\\\n",
    "                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)\n",
    "df_15M_perc_sub = df_15M_sub.drop(['parameter_code', 'dist_vlir','dist_lir',\\\n",
    "                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full dataframes for distance\n",
    "df_5M_dist = df_5M.drop(['parameter_code', 'perc_vlir','perc_lir',\\\n",
    "                       'perc_mir','perc_hir','perc_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)\n",
    "df_15M_dist = df_15M.drop(['parameter_code',  'perc_vlir','perc_lir',\\\n",
    "                       'perc_mir','perc_hir','perc_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)\n",
    "df_5M_dist['bin_half'] =df_5M_dist[['bin','half_indicator']].astype(str).apply(''.join,1)\n",
    "df_15M_dist['bin_half'] =df_15M_dist[['bin','half_indicator']].astype(str).apply(''.join,1)\n",
    "df_5M_dist=df_5M_dist.dropna()\n",
    "df_15M_dist=df_15M_dist.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create substitute dataframes for distance\n",
    "df_5M_dist_sub = df_5M_sub.drop(['parameter_code', 'perc_vlir','perc_lir',\\\n",
    "                       'perc_mir','perc_hir','perc_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)\n",
    "df_15M_dist_sub = df_15M_sub.drop(['parameter_code',  'perc_vlir','perc_lir',\\\n",
    "                       'perc_mir','perc_hir','perc_vhir',\\\n",
    "                       'total_avg_distance'], axis = 1)\n",
    "df_5M_dist_sub['bin_half'] =df_5M_dist_sub[['bin','half_indicator']].astype(str).apply(''.join,1)\n",
    "df_15M_dist_sub['bin_half'] =df_15M_dist_sub[['bin','half_indicator']].astype(str).apply(''.join,1)\n",
    "df_5M_dist_sub=df_5M_dist_sub.dropna()\n",
    "df_15M_dist_sub=df_15M_dist_sub.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_perc['bin_half'] =df_5M_perc[['bin','half_indicator']].astype(str).apply(''.join,1)\n",
    "df_15M_perc['bin_half'] =df_15M_perc[['bin','half_indicator']].astype(str).apply(''.join,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_perc_sub['bin_half'] =df_5M_perc_sub[['bin','half_indicator']].astype(str).apply(''.join,1)\n",
    "df_15M_perc_sub['bin_half'] =df_15M_perc_sub[['bin','half_indicator']].astype(str).apply(''.join,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_perc=df_5M_perc.dropna()\n",
    "df_15M_perc=df_15M_perc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_perc_sub=df_5M_perc_sub.dropna()\n",
    "df_15M_perc_sub=df_15M_perc_sub.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_dist_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distance speedzone 5M\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 30\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    " \n",
    "# Make a data frame\n",
    "\n",
    "#all game \n",
    "df= df_5M_dist.drop(['bin','half_indicator'],axis = 1) \n",
    "\n",
    "#substitutes avg distance\n",
    "#df = df_5M_avg_sub.drop(['bin','half_indicator'],axis = 1) \n",
    "#substitutes perc distance\n",
    "df = df_5M_dist_sub.drop(['bin','half_indicator'],axis = 1) \n",
    "\n",
    "# style\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    " \n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Greys_r')\n",
    "#print(palette)\n",
    "# multiple line plot\n",
    "num=0\n",
    "color = ['0.0', '0.25', '0.40', '0.55', '0.65','0.75']\n",
    "for column in df.drop(['bin_half'], axis=1):\n",
    "    num+=1\n",
    "    plt.plot(df['bin_half'], df[column], marker='', color = color[num]\n",
    "             , linewidth=3, alpha=0.9, label=column)\n",
    "    # Add legend\n",
    "    #valid locations are : right, center left, upper right, lower right, best center, lower left, center right, upper left\n",
    "    #upper center lower center\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1, title = 'Speedzone category',title_fontsize='15', fontsize = '15')\n",
    "    \n",
    "    # Add titles\n",
    "    #plt.title(\"Substitutes distance in speedzone 5 minute periods\", loc='left', fontsize=24, fontweight=0, color='black')\n",
    "    plt.xlabel(\"Period\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    #plt.savefig(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\average_distance_substitutes_5M_game.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distance speedzone 5M\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15,15)\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    " \n",
    "# Make a data frame\n",
    "#all game\n",
    "#df= df_5M_perc.drop(['bin','half_indicator'],axis = 1) \n",
    "#substitutes\n",
    "df= df_5M_perc_sub.drop(['bin','half_indicator'],axis = 1) \n",
    "\n",
    "# style\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    " \n",
    "color = ['0.0', '0.25', '0.40', '0.55', '0.65','0.75']\n",
    "\n",
    "# multiple line plot\n",
    "num=0\n",
    "for column in df.drop(['bin_half'], axis=1):\n",
    "    num+=1\n",
    "    plt.plot(df['bin_half'], df[column], marker='', color=color[num], linewidth=3, alpha=0.9, label=column)\n",
    " \n",
    "    # Add legend\n",
    "    #valid locations are : right, center left, upper right, lower right, best center, lower left, center right, upper left\n",
    "    #upper center lower center\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1, title = 'Speedzone category',title_fontsize='15', fontsize = '15')\n",
    "    \n",
    "    # Add titles\n",
    "    #plt.title(\"Substitutes percentage distance in speedzone 5M\", loc='left', fontsize=24, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Period\")\n",
    "    plt.ylabel(\"Percentage\")\n",
    "   # plt.savefig(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\percentage_distance_substitutes_5M_game.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot percentage speedzone 15M\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 30\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    " \n",
    "# Make a data frame\n",
    "#all match\n",
    "#df= df_15M_dist.drop(['bin','half_indicator'],axis = 1) \n",
    "#substitutes\n",
    "df= df_15M_perc_sub.drop(['bin','half_indicator'],axis = 1) \n",
    "#df = df1.loc[df1['bin_half'].isin['1S','2S','3S']]\n",
    "# style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    " \n",
    "# create a color palette\n",
    "color = ['0.0', '0.25', '0.40', '0.55', '0.65','0.75']\n",
    " \n",
    "# multiple line plot\n",
    "num=0\n",
    "for column in df.drop(['bin_half'], axis=1):\n",
    "    num+=1\n",
    "    plt.plot(df['bin_half'], df[column], marker='', color=color[num], linewidth=2, alpha=0.9, label=column)\n",
    " \n",
    "    # Add legend\n",
    "    #valid locations are : right, center left, upper right, lower right, best center, lower left, center right, upper left\n",
    "    #upper center lower center\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "    \n",
    "    # Add titles\n",
    "    #plt.title(\"Substitutes percentage distance in speedzone 15M bin\", loc='left', fontsize=24, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Period\")\n",
    "    plt.ylabel(\"Percentage\")\n",
    "    #plt.savefig(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\percentage_distance_substitutes_15M_game.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot percentage speedzone 15M\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 30\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    " \n",
    "# Make a data frame\n",
    "#all match\n",
    "df= df_15M_dist.drop(['bin','half_indicator'],axis = 1) \n",
    "#substitutes\n",
    "#df= df_15M_dist_sub.drop(['bin','half_indicator'],axis = 1) \n",
    "#df1= df_15M_dist.drop(['bin','half_indicator'],axis = 1) \n",
    "#df = df1.loc[df1['bin_half'].isin(['1S','2S','3S'])]\n",
    "# style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    " \n",
    "# create a color palette\n",
    "color = ['0.0', '0.25', '0.40', '0.55', '0.65','0.75']\n",
    "marker = [\"P\",\"*\",\"h\",\"H\",\"+\",\"x\"]\n",
    "data ={'X':['15','30','45','60','75','90']}\n",
    "dfx= pd.DataFrame(data, columns = ['X'])\n",
    " \n",
    "# multiple line plot\n",
    "num=0\n",
    "for column in df.drop(['bin_half'], axis=1):\n",
    "    num+=1\n",
    "    \n",
    "   \n",
    "    if column == 'dist_vlir':\n",
    "        label = 'Distance VLIR'\n",
    "    if column == 'dist_lir':\n",
    "        label = 'Distance LIR'\n",
    "    if column == 'dist_mir':\n",
    "        label = 'Distance MIR'\n",
    "    if column == 'dist_hir':\n",
    "        label = 'Distance HIR'\n",
    "    if column == 'dist_vhir':\n",
    "        label = 'Distance VHIR'\n",
    "        \n",
    "        \n",
    "        \n",
    "    #plt.plot(df['bin_half'], df[column], marker=marker[num], color=color[num], linewidth=2, alpha=0.9, label=label)\n",
    "    plt.plot(dfx['X'], df[column], marker=marker[num],markersize=14,  linewidth=2, alpha=0.9, label=label)\n",
    "\n",
    "    # Add legend\n",
    "    #valid locations are : right, center left, upper right, lower right, best center, lower left, center right, upper left\n",
    "    #upper center lower center\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "    \n",
    "    # Add titles\n",
    "    #plt.title(\"Substitutes distance in speedzone 15M bin\", loc='left', fontsize=24, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Period (Min)\")\n",
    "    plt.ylabel(\"Distance (M)\")\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.plot(dfx['X'], df[column])\n",
    "    #plt.savefig(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\distance_15M_game_Period.png\",bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## description of distance in speedzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data database\n",
    "df_5M = Get_aggregated_data('5M',9)\n",
    "df_5M_sub = Get_aggregated_data_sub('5M',9,)\n",
    "df_15M = Get_aggregated_data('15M',3)\n",
    "df_15M_sub = Get_aggregated_data_sub('15M',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis\n",
    "Anova difference between speedzones\n",
    "\n",
    "Determine difference between in substitutes and full match players !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole_match =  get_total_distance_speedzone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole_match.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_half =  get_total_distance_half_speedzone()\n",
    "\n",
    "#Difference between half's\n",
    "df_first_half = df_half[df_half['half_indicator']=='F']\n",
    "df_second_half = df_half[df_half['half_indicator']=='S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_half.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_half.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data database\n",
    "#df_5M = Get_aggregated_data('5M',9)\n",
    "#df_15M = Get_aggregated_data('15M',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,4):\n",
    "    \n",
    "    #full game\n",
    "    globals()['df_15M_dist_f_%s' % i] = df_15M.loc[(df_15M['bin']==i)& (df_15M['half_indicator']=='F')]\n",
    "    globals()['df_15M_dist_s_%s' % i] = df_15M.loc[(df_15M['bin']==i)& (df_15M['half_indicator']=='S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create excel-sheet\n",
    "with pd.ExcelWriter('15M_distance_in_speedzone_desc.xlsx') as writer:\n",
    "    df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (1,4):\n",
    "    print (\"bin 15\"+ str(j))\n",
    "    print ('f')\n",
    "    print(globals()['df_15M_dist_f_%s' % j].describe())\n",
    "    df = globals()['df_15M_dist_f_%s' % j].describe()\n",
    "    with pd.ExcelWriter('15M_distance_in_speedzone_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='15M_Distance_F_')\n",
    "    print('s')\n",
    "    print(globals()['df_15M_dist_s_%s' % j].describe())\n",
    "    df = globals()['df_15M_dist_s_%s' % j].describe()\n",
    "    with pd.ExcelWriter('15M_distance_in_speedzone_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='15M_Distance_S_')                 \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## description of 5 minutes entire match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create excel-sheet\n",
    "with pd.ExcelWriter('5M_distance_in_speedzone_desc.xlsx') as writer:\n",
    "    df.to_excel(writer)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    \n",
    "    #full game\n",
    "    globals()['df_5M_dist_f_%s' % i] = df_5M.loc[(df_5M['bin']==i)& (df_5M['half_indicator']=='F')]\n",
    "    globals()['df_5M_dist_s_%s' % i] = df_5M.loc[(df_5M['bin']==i)& (df_5M['half_indicator']=='S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (1,10):\n",
    "    print (\"bin 5m \"+ str(j))\n",
    "    print ('f')\n",
    "    print(globals()['df_5M_dist_f_%s' % j].describe())\n",
    "    df = globals()['df_5M_dist_f_%s' % j].describe()\n",
    "    with pd.ExcelWriter('5M_distance_in_speedzone_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='5M_Distance_F_')\n",
    "    print('s')\n",
    "    print(globals()['df_5M_dist_s_%s' % j].describe())\n",
    "    df = globals()['df_5M_dist_s_%s' % j].describe()\n",
    "    with pd.ExcelWriter('5M_distance_in_speedzone_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='5M_Distance_S_')   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## description substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole game has no use, first half neither\n",
    "df_half_sub =   get_total_distance_half_sub_speedzone()\n",
    "\n",
    "#Difference between half's\n",
    "df_first_half_sub = df_half_sub[df_half_sub['half_indicator']=='F']\n",
    "df_second_half_sub = df_half_sub[df_half_sub['half_indicator']=='S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create excel-sheet\n",
    "with pd.ExcelWriter('Half_distance_in_speedzone_desc.xlsx') as writer:\n",
    "    df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_second_half_sub.describe()\n",
    "#with pd.ExcelWriter('Half_distance_in_speedzone_desc.xlsx',\n",
    "#                    mode='a') as writer:  \n",
    "#     df.to_excel(writer, sheet_name='Half_Distance_S_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_half_sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,4):\n",
    "    \n",
    "    #substitutes\n",
    "    globals()['df_15M_dist_sub_f_%s' % i] = df_15M_sub.loc[(df_15M_sub['bin']==i)& (df_15M_sub['half_indicator']=='F')]\n",
    "    globals()['df_15M_dist_sub_s_%s' % i] = df_15M_sub.loc[(df_15M_sub['bin']==i)& (df_15M_sub['half_indicator']=='S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create excel-sheet\n",
    "df = pd.DataFrame()\n",
    "with pd.ExcelWriter('15M_distance_in_speedzone_sub_desc.xlsx') as writer:\n",
    "    df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (1,4):\n",
    "    print (\"bin 15\"+ str(j))\n",
    "    print ('f')\n",
    "    print(globals()['df_15M_dist_sub_f_%s' % j].describe())\n",
    "    df = globals()['df_15M_dist_sub_f_%s' % j].describe()\n",
    "    with pd.ExcelWriter('15M_distance_in_speedzone_sub_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='15M_Distance_sub_F_')\n",
    "    print('s')\n",
    "    print(globals()['df_15M_dist_sub_s_%s' % j].describe())\n",
    "    df = globals()['df_15M_dist_sub_s_%s' % j].describe()\n",
    "    with pd.ExcelWriter('15M_distance_in_speedzone_sub_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='15M_Distance_sub_S_')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    \n",
    "    #substitutes\n",
    "    globals()['df_5M_dist_sub_f_%s' % i] = df_5M_sub.loc[(df_5M_sub['bin']==i)& (df_5M_sub['half_indicator']=='F')]\n",
    "    globals()['df_5M_dist_sub_s_%s' % i] = df_5M_sub.loc[(df_5M_sub['bin']==i)& (df_5M_sub['half_indicator']=='S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create excel-sheet\n",
    "df = pd.DataFrame()\n",
    "with pd.ExcelWriter('5M_distance_in_speedzone_sub_desc.xlsx') as writer:\n",
    "    df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range (1,10):\n",
    "    print (\"bin 5\"+ str(j))\n",
    "    print ('f')\n",
    "    print(globals()['df_5M_dist_sub_f_%s' % j].describe())\n",
    "    df = globals()['df_5M_dist_sub_f_%s' % j].describe()\n",
    "    with pd.ExcelWriter('5M_distance_in_speedzone_sub_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='5M_Distance_sub_F_')\n",
    "    print('s')\n",
    "    print(globals()['df_5M_dist_sub_s_%s' % j].describe())\n",
    "    df = globals()['df_5M_dist_sub_s_%s' % j].describe()\n",
    "    with pd.ExcelWriter('5M_distance_in_speedzone_sub_desc.xlsx',\n",
    "                    mode='A') as writer:  \n",
    "         df.to_excel(writer, sheet_name='5M_Distance_sub_S_')         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data database\n",
    "df_5M_ano = Get_aggregated_data('5M',9)\n",
    "df_15M_ano = Get_aggregated_data('15M',3)\n",
    "df_5M_sub = Get_aggregated_data_sub('5M',9)\n",
    "df_15M_sub = Get_aggregated_data_sub('15M',3)\n",
    "df_half_ano = get_total_distance_half_speedzone()\n",
    "df_half_sub = get_total_distance_half_speedzone_sub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_half_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create different dataframes for first and second half and remove outliers\n",
    "for i in range (1,10):\n",
    "    \n",
    "    #full game\n",
    "    globals()['df_5M_ano_f_%s' % i] = df_5M_ano.loc[(df_5M_ano['bin']==i)& (df_5M_ano['half_indicator']=='F')]\n",
    "    globals()['df_5M_ano_s_%s' % i] = df_5M_ano.loc[(df_5M_ano['bin']==i)& (df_5M_ano['half_indicator']=='S')]\n",
    "    # substitutes\n",
    "    globals()['df_5M_sub_f_%s' % i] = df_5M_sub.loc[(df_5M_sub['bin']==i)& (df_5M_sub['half_indicator']=='F')]\n",
    "    globals()['df_5M_sub_s_%s' % i] = df_5M_sub.loc[(df_5M_sub['bin']==i)& (df_5M_sub['half_indicator']=='S')]\n",
    "    #globals()['df_5M_ano_f_%s' % i]['z'] = np.abs(stats.zscore(globals()['df_5M_ano_f_%s' % i]['total_avg_distance']))\n",
    "    #globals()['df_5M_ano_f_%s' % i] = globals()['df_5M_ano_f_%s' % i].loc[(globals()['df_5M_ano_f_%s' % i]['z']<2)]\n",
    "    #globals()['df_5M_ano_s_%s' % i]['z'] = np.abs(stats.zscore(globals()['df_5M_ano_s_%s' % i]['total_avg_distance']))\n",
    "    #globals()['df_5M_ano_s_%s' % i] = globals()['df_5M_ano_s_%s' % i].loc[(globals()['df_5M_ano_s_%s' % i]['z']<2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create different dataframes for first and second half and remove outliers\n",
    "for i in range (1,4):\n",
    "    \n",
    "    #full game\n",
    "    globals()['df_15M_ano_f_%s' % i] = df_15M_ano.loc[(df_15M_ano['bin']==i)& (df_15M_ano['half_indicator']=='F')]\n",
    "    globals()['df_15M_ano_s_%s' % i] = df_15M_ano.loc[(df_15M_ano['bin']==i)& (df_15M_ano['half_indicator']=='S')]\n",
    "    # substitutes\n",
    "    globals()['df_15M_sub_f_%s' % i] = df_15M_sub.loc[(df_15M_sub['bin']==i)& (df_15M_sub['half_indicator']=='F')]\n",
    "    globals()['df_15M_sub_s_%s' % i] = df_15M_sub.loc[(df_5M_sub['bin']==i)& (df_15M_sub['half_indicator']=='S')]\n",
    "    #globals()['df_15M_ano_f_%s' % i]['z'] = np.abs(stats.zscore(globals()['df_15M_ano_f_%s' % i]['total_avg_distance']))\n",
    "    #globals()['df_15M_ano_f_%s' % i] = globals()['df_15M_ano_f_%s' % i].loc[(globals()['df_15M_ano_f_%s' % i]['z']<2)]\n",
    "    #globals()['df_15M_ano_s_%s' % i]['z'] = np.abs(stats.zscore(globals()['df_5M_ano_s_%s' % i]['total_avg_distance']))\n",
    "    #globals()['df_5M_ano_s_%s' % i] = globals()['df_5M_ano_s_%s' % i].loc[(globals()['df_5M_ano_s_%s' % i]['z']<2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    #full game\n",
    "    globals()['df_half_ano_f_%s' %i] = df_half_ano.loc[(df_half_ano['half_indicator']=='F')]\n",
    "    globals()['df_half_ano_s_%s' %i] = df_half_ano.loc[(df_half_ano['half_indicator']=='S')]\n",
    "    #substitutes\n",
    "    globals()['df_half_sub_f_%s' %i] = df_half_sub.loc[(df_half_sub['half_indicator']=='F')]\n",
    "    globals()['df_half_sub_s_%s' %i] = df_half_sub.loc[(df_half_sub['half_indicator']=='S')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns for analysis, four sets : perc first half, percentage second half, distance first half distance second half per bin\n",
    "for i in range(1,10):\n",
    "    #full game \n",
    "    #globals()['df_5M_ano_perc_f_%s' % i] = globals()['df_5M_ano_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "    #                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "    #                       'total_avg_distance'], axis = 1)\n",
    "    #globals()['df_5M_ano_perc_s_%s' % i] = globals()['df_5M_ano_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "    #                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "    #                       'total_avg_distance'], axis = 1)\n",
    "    globals()['df_5M_ano_dist_f_%s' % i] = globals()['df_5M_ano_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "    globals()['df_5M_ano_dist_s_%s' % i] = globals()['df_5M_ano_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "    #substitutes\n",
    "    #globals()['df_5M_ano_sub_perc_f_%s' % i] = globals()['df_5M_ano_sub_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "                           #'dist_mir','dist_hir','dist_vhir',\\\n",
    "                           #'total_avg_distance'], axis = 1)\n",
    "    #globals()['df_5M_ano_sub_perc_s_%s' % i] = globals()['df_5M_sub_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "    #                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "    #                       'total_avg_distance'], axis = 1)\n",
    "    globals()['df_5M_ano_sub_dist_f_%s' % i] = globals()['df_5M_sub_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "    globals()['df_5M_ano_sub_dist_s_%s' % i] = globals()['df_5M_sub_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns for analysis, four sets : perc first half, percentage second half, distance first half distance second half per bin\n",
    "for i in range(1,4):\n",
    "    #full game \n",
    "    #globals()['df_15M_ano_perc_f_%s' % i] = globals()['df_15M_ano_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "    #                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "    #                       'total_avg_distance'], axis = 1)\n",
    "    #globals()['df_15M_ano_perc_s_%s' % i] = globals()['df_15M_ano_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "    #                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "    #                       'total_avg_distance'], axis = 1)\n",
    "    globals()['df_15M_ano_dist_f_%s' % i] = globals()['df_15M_ano_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "    globals()['df_15M_ano_dist_s_%s' % i] = globals()['df_15M_ano_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "    #substitutes\n",
    "    #globals()['df_5M_ano_sub_perc_f_%s' % i] = globals()['df_5M_ano_sub_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "                           #'dist_mir','dist_hir','dist_vhir',\\\n",
    "                           #'total_avg_distance'], axis = 1)\n",
    "    #globals()['df_15M_ano_sub_perc_s_%s' % i] = globals()['df_15M_sub_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'dist_vlir','dist_lir',\\\n",
    "    #                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "    #                       'total_avg_distance'], axis = 1)\n",
    "    globals()['df_15M_ano_sub_dist_f_%s' % i] = globals()['df_15M_sub_f_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "    globals()['df_15M_ano_sub_dist_s_%s' % i] = globals()['df_15M_sub_s_%s' % i].drop(['bin','parameter_code','half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir',\\\n",
    "                           'total_avg_distance'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns for analysis, four sets : perc first half, percentage second half, distance first half distance second half per bin\n",
    "for i in range(1,2):\n",
    "    #full game \n",
    "    globals()['df_half_dist_f%s' % i] = globals()['df_half_ano_f_%s' % i].drop(['half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir','game_id'\\\n",
    "                           ], axis = 1)\n",
    "    globals()['df_half_dist_s%s' % i] = globals()['df_half_ano_s_%s' % i].drop(['half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir','game_id'\\\n",
    "                           ], axis = 1)\n",
    "    #substitutes\n",
    "    globals()['df_half_dist_f%s' % i] = globals()['df_half_sub_f_%s' % i].drop(['half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir','game_id'\\\n",
    "                           ], axis = 1)\n",
    "    globals()['df_half_dist_s%s' % i] = globals()['df_half_sub_s_%s' % i].drop(['half_indicator', 'perc_vlir','perc_lir',\\\n",
    "                           'perc_mir','perc_hir','perc_vhir','game_id'\\\n",
    "                           ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_half_dist_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['df_half_dist_f%s' % 1].boxplot(column=['vlir', 'lir','mir','hir','vhir'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['df_5M_ano_sub_dist_s_%s' % 7].boxplot(column=['dist_vlir', 'dist_lir','dist_mir','dist_hir','dist_vhir'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['df_5M_ano_s_%s' % 1].boxplot(column=['perc_vlir', 'perc_lir','perc_mir','perc_hir','perc_vhir'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test normality full match KS 5 Min\n",
    "from scipy.stats import kstest\n",
    "\n",
    "x =''\n",
    "df_normality = pd.DataFrame([[x,x,x,x,x,x]],columns=['speedzone','bin','half','stat','p-value','same_distribution'])\n",
    "for j in range (1,10):\n",
    "    globals()['df_5M_ano_dist_f_%s' % j]\n",
    "    globals()['df_5M_ano_dist_s_%s' % j]\n",
    "    for i in range(0,5):\n",
    "        data_1 = globals()['df_5M_ano_dist_f_%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_5M_ano_dist_s_%s' % j].iloc[:,i]\n",
    "        #print(data_1)\n",
    "        stat, p = kstest(data_1,'norm')\n",
    "        stat_2, p_2 = kstest(data_2, 'norm')\n",
    "        column_name=globals()['df_5M_ano_dist_f_%s' % j].columns[i]\n",
    "        \n",
    "        print()\n",
    "        print('speedzone = ', column_name)\n",
    "        print('bin = %.3f'%(j))\n",
    "        print('_' * 70)\n",
    "        print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "                \n",
    "        if p>0.05:\n",
    "            print('Probably a normal distribution in the first half')\n",
    "            normal = 'a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'F',stat,p,normal]],columns=df_normality.columns))\n",
    "   \n",
    "        else:\n",
    "            print('Probably not a normal distribution in the first half')\n",
    "            normal = 'not a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'F',stat,p,normal]],columns=df_normality.columns))\n",
    "   \n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        print('stat=%.3f,p=%.3f'%(stat_2,p_2))\n",
    "        if p_2>0.05:\n",
    "            print('Probably a normal distribution in the second half')\n",
    "            normal = 'a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'S',stat_2,p_2,normal]],columns=df_normality.columns))\n",
    "        else:\n",
    "            print('Probably not a normal distribution in the second half')\n",
    "            normal = 'not a normal distribution'     \n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'S',stat_2,p_2,normal]],columns=df_normality.columns))\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "   # df_normality.to_csv(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\normality_dist_KS_full_match_5M.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test normality full match KS half\n",
    "from scipy.stats import kstest\n",
    "\n",
    "x =''\n",
    "df_normality = pd.DataFrame([[x,x,x,x,x,x]],columns=['speedzone','bin','half','stat','p-value','same_distribution'])\n",
    "for j in range (1,2):\n",
    "    globals()['df_half_dist_f%s' % j]\n",
    "    globals()['df_half_dist_s%s' % j]\n",
    "    for i in range(0,5):\n",
    "        data_1 = globals()['df_half_dist_f%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_half_dist_s%s' % j].iloc[:,i]\n",
    "        #print(data_1)\n",
    "        stat, p = kstest(data_1,'norm')\n",
    "        stat_2, p_2 = kstest(data_2, 'norm')\n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "        column_name=globals()['df_half_dist_f%s' % j].columns[i]\n",
    "        \n",
    "        print()\n",
    "        print('speedzone = ', column_name)\n",
    "        print('bin = %.3f'%(j))\n",
    "        print('_' * 70)\n",
    "        print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "                \n",
    "        if p>0.05:\n",
    "            print('Probably a normal distribution in the first half')\n",
    "            normal = 'a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'F',stat,p,normal]],columns=df_normality.columns))\n",
    "   \n",
    "        else:\n",
    "            print('Probably not a normal distribution in the first half')\n",
    "            normal = 'not a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'F',stat,p,normal]],columns=df_normality.columns))\n",
    "   \n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        print('stat=%.3f,p=%.3f'%(stat_2,p_2))\n",
    "        if p_2>0.05:\n",
    "            print('Probably a normal distribution in the second half')\n",
    "            normal = 'a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'S',stat_2,p_2,normal]],columns=df_normality.columns))\n",
    "        else:\n",
    "            print('Probably not a normal distribution in the second half')\n",
    "            normal = 'not a normal distribution'     \n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'S',stat_2,p_2,normal]],columns=df_normality.columns))\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['df_5M_ano_sub_dist_s_%s' % 7].boxplot(column=['dist_vlir', 'dist_lir','dist_mir','dist_hir','dist_vhir'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['df_5M_ano_sub_dist_s_%s' % 7].boxplot(column=['dist_vlir', 'dist_lir','dist_mir','dist_hir','dist_vhir'], grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#test normality substitutes\n",
    "from scipy.stats import shapiro\n",
    "x =''\n",
    "df_normality = pd.DataFrame([[x,x,x,x,x,x]],columns=['speedzone','bin','half','stat','p-value','same_distribution'])\n",
    "for j in range (1,4):\n",
    "    globals()['df_5M_ano_perc_f_%s' % j]\n",
    "    globals()['df_15M_ano_perc_s_%s' % j]\n",
    "    for i in range(0,5):\n",
    "        data_1 = globals()['df_15M_ano_perc_f_%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_15M_ano_perc_s_%s' % j].iloc[:,i]\n",
    "        #print(data_1)\n",
    "        norm_data_1,x1 = kstest(data_2, 'norm')\n",
    "        norm_data_2,x2 = kstest(data_2, 'norm')\n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "        column_name=globals()['df_15M_ano_perc_s_%s' % j].columns[i]\n",
    "        \n",
    "        print()\n",
    "        print('speedzone = ', column_name)\n",
    "        print('bin = %.3f'%(j))\n",
    "        print('_' * 70)\n",
    "        print('p_norm_f=%.3f,x=%.3f'%(norm_data_1,x1))\n",
    "                \n",
    "        if norm_data_1>=0.95:\n",
    "            print('Probably a normal distribution in the first half')\n",
    "        else:\n",
    "            print('Probably not a normal distribution in the first half')\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        if norm_data_1>=0.95:\n",
    "            print('Probably a normal distribution in the second half')\n",
    "            normal = 'a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'F',x1,1-norm_data_1,normal]],columns=df_normality.columns))\n",
    "        else:\n",
    "            print('Probably not a normal distribution in the second half')\n",
    "            normal = 'not a normal distribution'     \n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'F',x2,1-norm_data_1,normal]],columns=df_normality.columns))\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        if norm_data_2>=0.95:\n",
    "            print('Probably a normal distribution in the second half')\n",
    "            normal = 'a normal distribution'\n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'S',x2,1-norm_data_2,normal]],columns=df_normality.columns))\n",
    "        else:\n",
    "            print('Probably not a normal distribution in the second half')\n",
    "            normal = 'not a normal distribution'     \n",
    "            df_normality=df_normality.append(pd.DataFrame([[column_name,j,'S',x2,1-norm_data_2,normal]],columns=df_normality.columns))\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "#df_normality.to_csv(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\normality_perc_15M.csv\")\n",
    "print(df_normality)'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the bins have the same variance \n",
    "from scipy.stats import levene\n",
    "#for j in range (1,):\n",
    "j=1\n",
    "j2 = j+1\n",
    "j3 = j+2\n",
    "j4 = j+3\n",
    "j5 = j+4\n",
    "j6 = j+5\n",
    "j7 = j+6\n",
    "j8 = j+7\n",
    "j9 = j+8\n",
    "\n",
    "globals()['df_5M_ano_dist_f_%s' % j]\n",
    "globals()['df_5M_ano_dist_s_%s' % j]\n",
    "for i in range(0,5):\n",
    "    \n",
    "    data_1 = globals()['df_5M_ano_dist_f_%s' % j].iloc[:,i]\n",
    "    data_2 = globals()['df_5M_ano_dist_f_%s' % j2].iloc[:,i]\n",
    "    data_3 = globals()['df_5M_ano_dist_f_%s' % j3].iloc[:,i]\n",
    "    data_4 = globals()['df_5M_ano_dist_f_%s' % j4].iloc[:,i]\n",
    "    data_5 = globals()['df_5M_ano_dist_f_%s' % j5].iloc[:,i]\n",
    "    data_6 = globals()['df_5M_ano_dist_f_%s' % j6].iloc[:,i]\n",
    "    data_7 = globals()['df_5M_ano_dist_f_%s' % j7].iloc[:,i]\n",
    "    data_8 = globals()['df_5M_ano_dist_f_%s' % j8].iloc[:,i]\n",
    "    data_9 = globals()['df_5M_ano_dist_f_%s' % j9].iloc[:,i]\n",
    "    data_10 = globals()['df_5M_ano_dist_s_%s' % j].iloc[:,i]\n",
    "    data_11 = globals()['df_5M_ano_dist_s_%s' % j2].iloc[:,i]\n",
    "    data_12 = globals()['df_5M_ano_dist_s_%s' % j3].iloc[:,i]\n",
    "    data_13 = globals()['df_5M_ano_dist_s_%s' % j4].iloc[:,i]\n",
    "    data_14 = globals()['df_5M_ano_dist_s_%s' % j5].iloc[:,i]\n",
    "    data_15 = globals()['df_5M_ano_dist_s_%s' % j6].iloc[:,i]\n",
    "    data_16 = globals()['df_5M_ano_dist_s_%s' % j7].iloc[:,i]\n",
    "    data_17 = globals()['df_5M_ano_dist_s_%s' % j8].iloc[:,i]\n",
    "    data_18 = globals()['df_5M_ano_dist_s_%s' % j9].iloc[:,i]\n",
    "        \n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "    column_name=globals()['df_15M_ano_dist_s_%s' % j].columns[i]\n",
    "        \n",
    "    stat, p = levene(data_1,data_2,data_3,data_4,data_5,data_6,data_7,data_8,data_9,\\\n",
    "                    data_10,data_11,data_12,data_13,data_14,data_15,data_16,data_17,data_18)\n",
    "    print()\n",
    "    print('speedzone = ', column_name)\n",
    "    print('_' * 70)\n",
    "    print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "    if p>0.05:\n",
    "        print('Probably the same variance')\n",
    "    else:\n",
    "        print('Probably different variance')\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the bins have the same variance \n",
    "from scipy.stats import levene\n",
    "#for j in range (1,):\n",
    "j=1\n",
    "j2 = j+1\n",
    "j3 = j+2\n",
    "globals()['df_15M_ano_dist_f_%s' % j]\n",
    "globals()['df_15M_ano_dist_s_%s' % j]\n",
    "for i in range(0,5):\n",
    "    \n",
    "    data_1 = globals()['df_15M_ano_dist_f_%s' % j].iloc[:,i]\n",
    "    data_2 = globals()['df_15M_ano_dist_f_%s' % j2].iloc[:,i]\n",
    "    data_3 = globals()['df_15M_ano_dist_f_%s' % j3].iloc[:,i]\n",
    "    data_4 = globals()['df_15M_ano_dist_s_%s' % j].iloc[:,i]\n",
    "    data_5 = globals()['df_15M_ano_dist_s_%s' % j2].iloc[:,i]\n",
    "    data_6 = globals()['df_15M_ano_dist_s_%s' % j3].iloc[:,i]\n",
    "        \n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "    column_name=globals()['df_15M_ano_dist_s_%s' % j].columns[i]\n",
    "        \n",
    "    stat, p = levene(data_1,data_2,data_3,data_4,data_5,data_6)\n",
    "    print()\n",
    "    print('speedzone = ', column_name)\n",
    "    print('_' * 70)\n",
    "    print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "    if p>0.05:\n",
    "        print('Probably the same variance')\n",
    "    else:\n",
    "        print('Probably different variance')\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the halves have the same variance \n",
    "from scipy.stats import levene\n",
    "#for j in range (1,):\n",
    "j=1\n",
    "globals()['df_half_dist_f%s' % j]\n",
    "globals()['df_half_dist_s%s' % j]\n",
    "for i in range(0,5):\n",
    "    \n",
    "    data_1 = globals()['df_half_dist_f%s' % j].iloc[:,i]\n",
    "    data_2 = globals()['df_half_dist_s%s' % j].iloc[:,i]\n",
    "        \n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "    column_name=globals()['df_half_dist_s%s' % j].columns[i]\n",
    "        \n",
    "    stat, p = levene(data_1,data_2)\n",
    "    print()\n",
    "    print('speedzone = ', column_name)\n",
    "    print('_' * 70)\n",
    "    print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "    if p>0.05:\n",
    "        print('Probably the same variance')\n",
    "    else:\n",
    "        print('Probably different variance')\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 5min \n",
    "#Kruskal Wallis tests 5 minutes\n",
    "#change iloc for 0 vlir, 1 lir, 2 mir, 3 hir, 4 vhir\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import kruskal\n",
    "for i in range(0,5):\n",
    "    data_f_1 = globals()['df_5M_ano_dist_f_%s' % 1].iloc[:,i]\n",
    "    data_f_2 = globals()['df_5M_ano_dist_f_%s' % 2].iloc[:,i]\n",
    "    data_f_3 = globals()['df_5M_ano_dist_f_%s' % 3].iloc[:,i]\n",
    "    data_f_4 = globals()['df_5M_ano_dist_f_%s' % 4].iloc[:,i]\n",
    "    data_f_5 = globals()['df_5M_ano_dist_f_%s' % 5].iloc[:,i]\n",
    "    data_f_6 = globals()['df_5M_ano_dist_f_%s' % 6].iloc[:,i]\n",
    "    data_f_7 = globals()['df_5M_ano_dist_f_%s' % 7].iloc[:,i]\n",
    "    data_f_8 = globals()['df_5M_ano_dist_f_%s' % 8].iloc[:,i]\n",
    "    data_f_9 = globals()['df_5M_ano_dist_f_%s' % 9].iloc[:,i]\n",
    "    data_s_1 = globals()['df_5M_ano_dist_s_%s' % 1].iloc[:,i]\n",
    "    data_s_2 = globals()['df_5M_ano_dist_s_%s' % 2].iloc[:,i]\n",
    "    data_s_3 = globals()['df_5M_ano_dist_s_%s' % 3].iloc[:,i]\n",
    "    data_s_4 = globals()['df_5M_ano_dist_s_%s' % 1].iloc[:,i]\n",
    "    data_s_5 = globals()['df_5M_ano_dist_s_%s' % 2].iloc[:,i]\n",
    "    data_s_6 = globals()['df_5M_ano_dist_s_%s' % 3].iloc[:,i]\n",
    "    data_s_7 = globals()['df_5M_ano_dist_s_%s' % 1].iloc[:,i]\n",
    "    data_s_8 = globals()['df_5M_ano_dist_s_%s' % 2].iloc[:,i]\n",
    "    data_s_9 = globals()['df_5M_ano_dist_s_%s' % 3].iloc[:,i]\n",
    "    if i == 0:\n",
    "        speedzone = 'vlir'\n",
    "    if i == 1:\n",
    "        speedzone = 'lir'\n",
    "    if i == 2:\n",
    "        speedzone = 'mir'\n",
    "    if i == 3:\n",
    "        speedzone = 'hir'\n",
    "    if i ==4:\n",
    "        speedzone = 'vhir'\n",
    "    stat, p = kruskal(data_f_1,data_f_2,data_f_3,\\\n",
    "                      data_f_4,data_f_5,data_f_6,\\\n",
    "                      data_f_7,data_f_8,data_f_9,\\\n",
    "                      data_s_1,data_s_2,data_s_3,\\\n",
    "                      data_s_4,data_s_5,data_s_6,\\\n",
    "                      data_s_7,data_s_8,data_s_9)\n",
    "    print()\n",
    "    print('speedzone = %s'% speedzone)\n",
    "    print(stat,p)\n",
    "    if p<0.05:\n",
    "        print('reject the null hypothesis that the median is the same for all bins')\n",
    "    if p>0.05:\n",
    "        print('accept the null hypothesis that the median is the same for all bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " stat, p = kruskal(data_f_1,data_f_2,data_f_3,data_s_1,data_s_2,data_s_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 15min lir\n",
    "#Kruskal Wallis tests 15 minutes\n",
    "#change iloc for 0 vlir, 1 lir, 2 mir, 3 hir, 4 vhir\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import kruskal\n",
    "for i in range(0,5):\n",
    "    data_f_1 = globals()['df_15M_ano_dist_f_%s' % 1].iloc[:,i]\n",
    "    data_f_2 = globals()['df_15M_ano_dist_f_%s' % 2].iloc[:,i]\n",
    "    data_f_3 = globals()['df_15M_ano_dist_f_%s' % 3].iloc[:,i]\n",
    "    data_s_1 = globals()['df_15M_ano_dist_s_%s' % 1].iloc[:,i]\n",
    "    data_s_2 = globals()['df_15M_ano_dist_s_%s' % 2].iloc[:,i]\n",
    "    data_s_3 = globals()['df_15M_ano_dist_s_%s' % 3].iloc[:,i]\n",
    "    if i == 0:\n",
    "        speedzone = 'vlir'\n",
    "    if i == 1:\n",
    "        speedzone = 'lir'\n",
    "    if i == 2:\n",
    "        speedzone = 'mir'\n",
    "    if i == 3:\n",
    "        speedzone = 'hir'\n",
    "    if i ==4:\n",
    "        speedzone = 'vhir'\n",
    "    stat, p = kruskal(data_f_1,data_f_2,data_f_3,data_s_1,data_s_2,data_s_3)\n",
    "    print()\n",
    "    print('speedzone = %s'% speedzone)\n",
    "    print(stat,p)\n",
    "    if p<0.05:\n",
    "        print('reject the null hypothesis that the median is the same for all bins')\n",
    "    if p>0.05:\n",
    "        print('accept the null hypothesis that the median is the same for all bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 15min lir\n",
    "#Kruskal Wallis tests 15 minutes\n",
    "#change iloc for 0 vlir, 1 lir, 2 mir, 3 hir, 4 vhir\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import kruskal\n",
    "for i in range(0,5):\n",
    "    data_f_1 = globals()['df_half_dist_f%s' % 1].iloc[:,i]\n",
    "    data_s_1 = globals()['df_half_dist_s%s' % 1].iloc[:,i]\n",
    "    \n",
    "    if i == 0:\n",
    "        speedzone = 'vlir'\n",
    "    if i == 1:\n",
    "        speedzone = 'lir'\n",
    "    if i == 2:\n",
    "        speedzone = 'mir'\n",
    "    if i == 3:\n",
    "        speedzone = 'hir'\n",
    "    if i ==4:\n",
    "        speedzone = 'vhir'\n",
    "    stat, p = kruskal(data_f_1,data_f_2)\n",
    "    print()\n",
    "    print('speedzone = %s'% speedzone)\n",
    "    print(stat,p)\n",
    "    if p<0.05:\n",
    "        print('reject the null hypothesis that the median is the same for all bins')\n",
    "    if p>0.05:\n",
    "        print('accept the null hypothesis that the median is the same for all bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_f_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post hoc Kruskal Wallis post conover 5 min\n",
    "import scikit_posthocs as sp\n",
    "for i in range(0,5):\n",
    "    data_f_1 = globals()['df_5M_ano_dist_f_%s' % 1].iloc[:,i]\n",
    "    data_f_2 = globals()['df_5M_ano_dist_f_%s' % 2].iloc[:,i]\n",
    "    data_f_3 = globals()['df_5M_ano_dist_f_%s' % 3].iloc[:,i]\n",
    "    data_f_4 = globals()['df_5M_ano_dist_f_%s' % 4].iloc[:,i]\n",
    "    data_f_5 = globals()['df_5M_ano_dist_f_%s' % 5].iloc[:,i]\n",
    "    data_f_6 = globals()['df_5M_ano_dist_f_%s' % 6].iloc[:,i]\n",
    "    data_f_7 = globals()['df_5M_ano_dist_f_%s' % 7].iloc[:,i]\n",
    "    data_f_8 = globals()['df_5M_ano_dist_f_%s' % 8].iloc[:,i]\n",
    "    data_f_9 = globals()['df_5M_ano_dist_f_%s' % 9].iloc[:,i]\n",
    "    data_s_1 = globals()['df_5M_ano_dist_s_%s' % 1].iloc[:,i]\n",
    "    data_s_2 = globals()['df_5M_ano_dist_s_%s' % 2].iloc[:,i]\n",
    "    data_s_3 = globals()['df_5M_ano_dist_s_%s' % 3].iloc[:,i]\n",
    "    data_s_4 = globals()['df_5M_ano_dist_s_%s' % 4].iloc[:,i]\n",
    "    data_s_5 = globals()['df_5M_ano_dist_s_%s' % 5].iloc[:,i]\n",
    "    data_s_6 = globals()['df_5M_ano_dist_s_%s' % 6].iloc[:,i]\n",
    "    data_s_7 = globals()['df_5M_ano_dist_s_%s' % 7].iloc[:,i]\n",
    "    data_s_8 = globals()['df_5M_ano_dist_s_%s' % 8].iloc[:,i]\n",
    "    data_s_9 = globals()['df_5M_ano_dist_s_%s' % 9].iloc[:,i]\n",
    "    if i == 0:\n",
    "        speedzone = 'vlir'\n",
    "    if i == 1:\n",
    "        speedzone = 'lir'\n",
    "    if i == 2:\n",
    "        speedzone = 'mir'\n",
    "    if i == 3:\n",
    "        speedzone = 'hir'\n",
    "    if i ==4:\n",
    "        speedzone = 'vhir'\n",
    "    df =pd.DataFrame()\n",
    "    \n",
    "    df['f1']=pd.Series(data_f_1.values)\n",
    "    df['f2']=pd.Series(data_f_2.values)\n",
    "    df['f3']=pd.Series(data_f_3.values)\n",
    "    df['f4']=pd.Series(data_f_4.values)\n",
    "    df['f5']=pd.Series(data_f_5.values)\n",
    "    df['f6']=pd.Series(data_f_6.values)\n",
    "    df['f7']=pd.Series(data_f_7.values)\n",
    "    df['f8']=pd.Series(data_f_8.values)\n",
    "    df['f9']=pd.Series(data_f_9.values)\n",
    "    df['s1']=pd.Series(data_s_1.values)\n",
    "    df['s2']=pd.Series(data_s_2.values)\n",
    "    df['s3']=pd.Series(data_s_3.values)\n",
    "    df['s4']=pd.Series(data_s_4.values)\n",
    "    df['s5']=pd.Series(data_s_5.values)\n",
    "    df['s6']=pd.Series(data_s_6.values)\n",
    "    df['s7']=pd.Series(data_s_7.values)\n",
    "    df['s8']=pd.Series(data_s_8.values)\n",
    "    df['s9']=pd.Series(data_s_9.values)\n",
    "    \n",
    "    stacked_data = df.stack().reset_index()\n",
    "    stacked_data = stacked_data.rename(columns={'level_0':'id',\n",
    "                                        'level_1':'bin',\n",
    "                                         0:'distance'})\n",
    "    print(speedzone)\n",
    "    print('_' * 70)\n",
    "    pd.set_option('display.float_format', lambda x: f'{x:,.5f}')\n",
    "    print(sp.posthoc_conover(stacked_data, val_col='distance', group_col='bin'))\n",
    "    \n",
    "    print('_' * 70)\n",
    "    \n",
    "    \n",
    "    # \n",
    "    #the null hypothesis is that the groups don't differ in their distance\n",
    "    #Pairwise comparisons show that we may reject the null hypothesis (p < 0.01), the groups do differ\n",
    "    #Pairwise comparisons show that we may accept the null hypothesis (p > 0.01), the groups do not differ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post hoc Kruskal Wallis post conover 15 min\n",
    "import scikit_posthocs as sp\n",
    "for i in range(0,5):\n",
    "    data_f_1 = globals()['df_15M_ano_dist_f_%s' % 1].iloc[:,i]\n",
    "    data_f_2 = globals()['df_15M_ano_dist_f_%s' % 2].iloc[:,i]\n",
    "    data_f_3 = globals()['df_15M_ano_dist_f_%s' % 3].iloc[:,i]\n",
    "    data_s_1 = globals()['df_15M_ano_dist_s_%s' % 1].iloc[:,i]\n",
    "    data_s_2 = globals()['df_15M_ano_dist_s_%s' % 2].iloc[:,i]\n",
    "    data_s_3 = globals()['df_15M_ano_dist_s_%s' % 3].iloc[:,i]\n",
    "    if i == 0:\n",
    "        speedzone = 'vlir'\n",
    "    if i == 1:\n",
    "        speedzone = 'lir'\n",
    "    if i == 2:\n",
    "        speedzone = 'mir'\n",
    "    if i == 3:\n",
    "        speedzone = 'hir'\n",
    "    if i ==4:\n",
    "        speedzone = 'vhir'\n",
    "    df =pd.DataFrame()\n",
    "    df['f1']=data_f_1.values\n",
    "    df['f2']=data_f_2.values\n",
    "    df['f3']=data_f_3.values\n",
    "    df['s1']=data_s_1.values\n",
    "    df['s2']=data_s_2.values\n",
    "    df['s3']=data_s_3.values\n",
    "    stacked_data = df.stack().reset_index()\n",
    "    stacked_data = stacked_data.rename(columns={'level_0':'id',\n",
    "                                        'level_1':'bin',\n",
    "                                         0:'distance'})\n",
    "    print(speedzone)\n",
    "    print('_' * 70)\n",
    "    pd.set_option('display.float_format', lambda x: f'{x:,.5f}')\n",
    "    print(sp.posthoc_conover(stacked_data, val_col='distance', group_col='bin'))\n",
    "    \n",
    "    print('_' * 70)\n",
    "    \n",
    "    \n",
    "   #the null hypothesis is that the groups don't differ in their distance\n",
    "    #Pairwise comparisons show that we may reject the null hypothesis (p < 0.01), the groups do differ\n",
    "    #Pairwise comparisons show that we may accept the null hypothesis (p > 0.01), the groups do not differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### post hoc Kruskal Wallis post conover halves\n",
    "import scikit_posthocs as sp\n",
    "for i in range(0,5):\n",
    "    data_f_1 = globals()['df_half_dist_f%s' % 1].iloc[:,i]\n",
    "    data_s_1 = globals()['df_half_dist_s%s' % 1].iloc[:,i]\n",
    "    if i == 0:\n",
    "        speedzone = 'vlir'\n",
    "    if i == 1:\n",
    "        speedzone = 'lir'\n",
    "    if i == 2:\n",
    "        speedzone = 'mir'\n",
    "    if i == 3:\n",
    "        speedzone = 'hir'\n",
    "    if i ==4:\n",
    "        speedzone = 'vhir'\n",
    "    df =pd.DataFrame()\n",
    "    df['f1']=data_f_1.values\n",
    "    df['s1']=data_s_1.values\n",
    "    stacked_data = df.stack().reset_index()\n",
    "    stacked_data = stacked_data.rename(columns={'level_0':'id',\n",
    "                                        'level_1':'bin',\n",
    "                                         0:'distance'})\n",
    "    print(speedzone)\n",
    "    print('_' * 70)\n",
    "    pd.set_option('display.float_format', lambda x: f'{x:,.5f}')\n",
    "    print(sp.posthoc_conover(stacked_data, val_col='distance', group_col='bin'))\n",
    "    \n",
    "    print('_' * 70)\n",
    "    \n",
    "    \n",
    "   #the null hypothesis is that the groups don't differ in their distance\n",
    "    #Pairwise comparisons show that we may reject the null hypothesis (p < 0.01), the groups do differ\n",
    "    #Pairwise comparisons show that we may accept the null hypothesis (p > 0.01), the groups do not differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from statsmodels.stats.multicomp import (pairwise_tukeyhsd,\n",
    "                                         MultiComparison)\n",
    "\n",
    "# Set up the data for comparison (creates a specialised object)\n",
    "MultiComp = MultiComparison(stacked_data['distance'],\n",
    "                            stacked_data['bin'])\n",
    "\n",
    "# Show all pair-wise comparisons:\n",
    "\n",
    "# Print the comparisons\n",
    "\n",
    "print(MultiComp.tukeyhsd().summary())\n",
    "\n",
    "#KS test and full match\n",
    "from scipy.stats import f_oneway\n",
    "df_mean = pd.DataFrame([[x,x,x,x,x,x]],columns=['speedzone','bin','half','stat','p-value','same_distribution'])\n",
    "from scipy.stats import ttest_ind\n",
    "for j in range (1,3):\n",
    "    globals()['df_15M_ano_perc_f_%s' % j]\n",
    "    globals()['df_15M_ano_perc_s_%s' % j]\n",
    "    for i in range(0,5):\n",
    "        data_1 = globals()['df_15M_ano_perc_f_%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_15M_ano_perc_s_%s' % j].iloc[:,i]\n",
    "        #stats.shapiro()\n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "        column_name=globals()['df_15M_ano_perc_s_%s' % j].columns[i]\n",
    "        \n",
    "        #stat, p = ttest_ind(data_1, data_2)\n",
    "        stat, p = f_oneway(data_1,data_2)\n",
    "        print()\n",
    "        print('speedzone = ', column_name)\n",
    "        print('bin = %.3f'%(j))\n",
    "        print('_' * 70)\n",
    "        print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "        if p > 0.05:\n",
    "            print('Accept null hypothesis that the means are equal.')\n",
    "            equal = 'equal'\n",
    "        else:\n",
    "            print('Reject the null hypothesis that the means are not equal.')\n",
    "            equal = 'not equal'\n",
    "        \n",
    "        df_mean=df_mean.append(pd.DataFrame([[column_name,j,'S',stat,p,equal]],columns=df_mean.columns))\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "#df_mean.to_csv(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\mean_distance_15M_full_match.csv\")\n",
    "             \n",
    "\n",
    "# do the bins have the same distribution KS test\n",
    "from scipy.stats import ks_2samp\n",
    "x='1'\n",
    "ks_dataframe = pd.DataFrame([[x,x,x,x,x,x]],columns=['speedzone','bin1','bin2','stat','p-value','same_distribution'])\n",
    "for j in range (1,3):\n",
    "    #globals()['df_5M_ano_f_%s' % j]\n",
    "    globals()['df_5M_ano_dist_s_%s' % j]\n",
    "    for i in range(0,5):\n",
    "        j2 = j+1\n",
    "        data_1 = globals()['df_5M_ano_dist_s_%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_5M_ano_dist_s_%s' % j2].iloc[:,i]\n",
    "        \n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "        stat,p= ks_2samp(data_1,data_2)\n",
    "        column_name=globals()['df_5M_ano_dist_s_%s' % j].columns[i]\n",
    "        sns.kdeplot(data_1,label=column_name+' '+ str(j))\n",
    "        sns.kdeplot(data_2,label=column_name+' '+ str(j2))\n",
    "  \n",
    "        # Plot formatting\n",
    "        plt.legend(prop={'size': 16}, title = 'bins')\n",
    "        plt.title('Density Plot %s ' %column_name+' '+ str(j) +' '+str(j2))\n",
    "        plt.xlabel('Distance')\n",
    "        plt.ylabel('Density')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the bins have the same distribution KS test\n",
    "from scipy.stats import ks_2samp\n",
    "x='1'\n",
    "ks_dataframe = pd.DataFrame([[x,x,x,x,x,x]],columns=['speedzone','bin1','bin2','stat','p-value','same_distribution'])\n",
    "for j in range (1,3):\n",
    "    #globals()['df_5M_ano_f_%s' % j]\n",
    "    globals()['df_5M_ano_s_%s' % j]\n",
    "    for i in range(0,5):\n",
    "        j2 = j+1\n",
    "        data_1 = globals()['df_5M_ano_dist_s_%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_5M_ano_dist_s_%s' % j].iloc[:,i]\n",
    "        \n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "        stat,p= ks_2samp(data_1,data_2)\n",
    "        column_name=globals()['df_5M_ano_dist_s_%s' % j].columns[i]\n",
    "        sns.kdeplot(data_1,label=column_name+' '+ str(j))\n",
    "        sns.kdeplot(data_2,label=column_name+' '+ str(j2))\n",
    "  \n",
    "        # Plot formatting\n",
    "        plt.legend(prop={'size': 16}, title = 'bins')\n",
    "        plt.title('Density Plot %s ' %column_name+' '+ str(j) +' '+str(j2))\n",
    "        plt.xlabel('Distance')\n",
    "        plt.ylabel('Density')\n",
    "        print()\n",
    "        print('speedzone = ', column_name)\n",
    "        print('bin = %.3f'%(j))\n",
    "        print('bin = %.3f'%(j2))\n",
    "        print('_' * 70)\n",
    "        print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "        if p>0.10:\n",
    "            print('Probably the same KS distribution')\n",
    "            same = 'true'\n",
    "        else:\n",
    "            print('Probably a different KS distribution')\n",
    "            same = 'false' \n",
    "        ks_dataframe=ks_dataframe.append(pd.DataFrame([[column_name,j,j2,stat,p,same]],columns=ks_dataframe.columns))\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    #ks_dataframe.to_csv(r\"C:\\Users\\talko\\OneDrive - Hanzehogeschool Groningen\\Research\\Football\\Notebooks\\results\\ks_second_half_5M.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference between bins in the second half anova\n",
    "from scipy.stats import f_oneway\n",
    "for j in range (1,9):\n",
    "    globals()['df_5M_ano_s_%s' % j]\n",
    "    for i in range(0,5):\n",
    "        j2 = j+1\n",
    "        data_1 = globals()['df_5M_ano_s_%s' % j].iloc[:,i]\n",
    "        data_2 = globals()['df_5M_ano_s_%s' % j2].iloc[:,i]\n",
    "        #print(data_1.head())\n",
    "        #print (data_2.head())\n",
    "        #j1=j+1\n",
    "        #data_2 = globals()['df_5M_ano_f_%s' % j1].iloc[:,i]\n",
    "        column_name=globals()['df_5M_ano_s_%s' % j].columns[i]\n",
    "        \n",
    "        stat, p = f_oneway(data_1,data_2)\n",
    "        print()\n",
    "        print('speedzone = ', column_name)\n",
    "        print('bin = %.3f'%(j))\n",
    "        print('bin = %.3f'%(j2))\n",
    "        print('_' * 70)\n",
    "        print('stat=%.3f,p=%.3f'%(stat,p))\n",
    "        if p>0.05:\n",
    "            print('Probably the same distribution')\n",
    "        else:\n",
    "            print('Probably different distribution')\n",
    "        print('_' * 70)\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_perc_lessthan5_5M_data():\n",
    "      \n",
    "    \n",
    "    #ball,keeper and referree are excluded\n",
    "    sql=\"select BIN_1\\\n",
    "                ,BIN_2\\\n",
    "                ,BIN_3\\\n",
    "                ,BIN_4\\\n",
    "                ,BIN_5\\\n",
    "                ,BIN_6\\\n",
    "                ,BIN_7\\\n",
    "                ,BIN_8\\\n",
    "                ,BIN_9\\\n",
    "                ,BIN_10\\\n",
    "                ,BIN_11\\\n",
    "                ,BIN_12\\\n",
    "                ,BIN_13\\\n",
    "                ,BIN_14\\\n",
    "                ,BIN_15\\\n",
    "                ,BIN_16\\\n",
    "                ,BIN_17\\\n",
    "                ,BIN_18\\\n",
    "           from PERC_LESSTHAN5_5M_V\"\n",
    "         \n",
    "    df = pd.read_sql(sql, con=engine)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_than5_5m = Get_perc_lessthan5_5M_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = less_than5_5m.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ANOVA table as R like output\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# reshape the d dataframe suitable for statsmodels package \n",
    "d_melt = pd.melt(d.reset_index(), id_vars=['index'], value_vars=['bin_9','bin_10','bin_11','bin_12','bin_13','bin_14'\\\n",
    "                                                                ,'bin_15','bin_16','bin_17','bin_18'])\n",
    "# replace column names\n",
    "d_melt.columns = ['index', 'bin', 'value']\n",
    "# Ordinary Least Squares (OLS) model\n",
    "model = ols('value ~ C(bin)', data=d_melt).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table\n",
    "\n",
    "#there are significant differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairwise comparison\n",
    "# load packages\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog=d_melt['value'], groups=d_melt['bin'], alpha=0.05)\n",
    "print(m_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_aggregated_ks_data(parameter_code,bin, half_indicator):\n",
    "      \n",
    "    \n",
    "    #ball,keeper and referree are excluded\n",
    "    sql=\"select BIN\\\n",
    "         ,      player_id\\\n",
    "         ,      game_id\\\n",
    "         ,      PARAMETER_CODE\\\n",
    "         ,      HALF_INDICATOR\\\n",
    "         ,round(avg(AVG_LESSTHAN5),1) avg_lessthan5\\\n",
    "         ,round(avg(PERC_LESSTHAN5),1) perc_lessthan5\\\n",
    "         ,round(avg(AVG_BETWEEN5AND10),1) avg_between5and10\\\n",
    "         ,round(avg(PERC_BETWEEN5AND10),1) perc_between5and10\\\n",
    "         ,round(avg(AVG_BETWEEN10AND15),1) avg_between10and15\\\n",
    "         ,round(avg(PERC_BETWEEN10AND15),1) perc_between10and15\\\n",
    "         ,round(avg(AVG_BETWEEN15AND20),1) avg_between15and20\\\n",
    "         ,round(avg(PERC_BETWEEN15AND20),1) perc_between15and20\\\n",
    "         ,round(avg(AVG_BETWEEN20AND25),1) avg_between20and25\\\n",
    "         ,round(avg(PERC_BETWEEN20AND25),1) perc_between20and25\\\n",
    "         ,round(avg(AVG_BETWEEN25AND30),1) avg_between25and30\\\n",
    "         ,round(avg(PERC_BETWEEN25AND30),1) perc_between25and30\\\n",
    "         ,round(avg(AVG_MORETHAN30),1) avg_morethan30\\\n",
    "         ,round(avg(PERC_MORETHAN30),1) perc_morethan30\\\n",
    "         ,avg(TOTAL_AVG_DISTANCE) total_avg_distance\\\n",
    "         from perc_dist_in_speedzone_game_v\\\n",
    "         where parameter_code like :parameter_code\\\n",
    "         and bin = :bin \\\n",
    "         and half_indicator like :half_indicator\\\n",
    "         group by bin,half_indicator, parameter_code,player_id,game_id\\\n",
    "         order by half_indicator,bin asc\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'parameter_code' :parameter_code,'bin' : bin,'half_indicator' : half_indicator}, con=engine)\n",
    "    return df\n",
    "# ,round(avg(PERC_BETWEEN5AND10),1) perc_between5and10\\\n",
    "#,round(avg(PERC_BETWEEN10AND15),1) perc_between10and15\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_1_F = Get_aggregated_ks_data('15M',3,'F')\n",
    "df_5M_9_S = Get_aggregated_ks_data('15M',3,'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_1_F_ks  = df_5M_1_F.drop(['bin','player_id','game_id','parameter_code','half_indicator', 'perc_lessthan5','perc_between5and10',\\\n",
    "                           'perc_between10and15','perc_between15and20','perc_between20and25','perc_between25and30','perc_morethan30',\\\n",
    "                           'total_avg_distance'], axis = 1)\n",
    "df_5M_9_S_ks = df_5M_9_S.drop(['bin','player_id','game_id','parameter_code','half_indicator', 'perc_lessthan5','perc_between5and10',\\\n",
    "                           'perc_between10and15','perc_between15and20','perc_between20and25','perc_between25and30','perc_morethan30',\\\n",
    "                           'total_avg_distance'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=list(df_5M_1_F_ks.iloc[0, :])\n",
    "data2=list(df_5M_9_S_ks.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=df_5M_1_F_ks.iloc[:,1]\n",
    "data2=df_5M_9_S_ks.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=df_5M_1_F_ks\n",
    "data2=df_5M_9_S_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data_1,label='F')\n",
    "sns.kdeplot(data_2,label='S')\n",
    "  \n",
    "# Plot formatting\n",
    "plt.legend(prop={'size': 16}, title = 'bins')\n",
    "plt.title('Density Plot speedzone between 5 and 10 KM, 3th quarter')\n",
    "plt.xlabel('Meters')\n",
    "plt.ylabel('Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "ax = sns.kdeplot(data1, shade=True, color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# timeseries correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get anova data database\n",
    "df_5M_tsc =Get_aggregated_data_sub('5M',9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_tsc['bin_half'] =df_5M_tsc[['bin','half_indicator']].astype(str).apply(''.join,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_tsc = df_5M_tsc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_tsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_tsc_perc =df_5M_tsc.drop(['bin','parameter_code','half_indicator','dist_vlir','dist_lir',\\\n",
    "                       'dist_mir','dist_hir','dist_vhir',\\\n",
    "                       'total_avg_distance'\\\n",
    "                       ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_tsc_perc.set_index('bin_half')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df_5M_tsc_perc.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat.to_csv('correlation_subst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize =(9, 8)) \n",
    "sns_plot=sns.heatmap(corrmat, ax = ax, cmap =\"Greys\", linewidths = 0.1)\n",
    "plt.savefig(\"'correlation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendall_pval(x,y):\n",
    "    return format(kendalltau(x,y)[1],'f')\n",
    "\n",
    "def pearsonr_pval(x,y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "def spearmanr_pval(x,y):\n",
    "    return spearmanr(x,y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M_tsc_perc.corr(method=pearsonr_pval).to_csv('lit_p-values_correlation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
