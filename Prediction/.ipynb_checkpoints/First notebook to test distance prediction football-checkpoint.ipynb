{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import model_selection\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"oracle://{user}:{pw}@145.33.225.194/{db}\"\n",
    "                       .format(user=\"football_select\",\n",
    "                               pw=\"\",\n",
    "                               db=\"orcl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Get_aggregated_data_full_game(game_id, player_id,parameter_code):\n",
    "    if game_id == '':\n",
    "        game_id = '%'\n",
    "    if player_id == '':\n",
    "        player_id = '%'\n",
    "    \n",
    "    \n",
    "    sql=\"select game_id\\\n",
    "       , player_id\\\n",
    "       , parameter_code\\\n",
    "       , order_column_continue_f(p_order_column =>order_column,\\\n",
    "                                                   p_half_indicator =>half_indicator,\\\n",
    "                                                   p_parameter_code =>parameter_code,\\\n",
    "                                                   p_player_id =>player_id,\\\n",
    "                                                   p_game_id =>game_id,\\\n",
    "                                                   p_difference_start_end_prr_ind => 'F')order_column\\\n",
    "       ,      distance\\\n",
    "       ,      sum_distance\\\n",
    "       ,      reached_avg_total_distance\\\n",
    "       from agg_game_rolling_avg_tot_distance_ind_v\\\n",
    "       where parameter_code like : parameter_code\\\n",
    "       and player_id =:player_id\\\n",
    "       and game_id like : game_id\\\n",
    "       and difference_start_end_prr_ind like 'T'\\\n",
    "       order by game_id,order_column\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'game_id':game_id,'player_id':player_id, 'parameter_code' :parameter_code}, con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Get_aggregated_data_not_full_game(game_id, player_id,parameter_code):\n",
    "    if game_id == '':\n",
    "        game_id = '%'\n",
    "    if player_id == '':\n",
    "        player_id = '%'\n",
    "    \n",
    "    \n",
    "    sql=\"select game_id\\\n",
    "       , player_id\\\n",
    "       , parameter_code\\\n",
    "       , order_column_continue_f(p_order_column =>order_column,\\\n",
    "                                                   p_half_indicator =>half_indicator,\\\n",
    "                                                   p_parameter_code =>parameter_code,\\\n",
    "                                                   p_player_id =>player_id,\\\n",
    "                                                   p_game_id =>game_id,\\\n",
    "                                                   p_difference_start_end_prr_ind => 'F')order_column\\\n",
    "       ,      distance\\\n",
    "       ,      sum_distance\\\n",
    "       from AGG_GAME_ROLLING_AVG_DISTANCE_V\\\n",
    "       where parameter_code like : parameter_code\\\n",
    "       and player_id =:player_id\\\n",
    "       and game_id like : game_id\\\n",
    "       and full_game_ind like 'F'\\\n",
    "       order by game_id,order_column\"\n",
    "         \n",
    "    df = pd.read_sql(sql,params={'game_id':game_id,'player_id':player_id, 'parameter_code' :parameter_code}, con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_players (game_id,player_id):\n",
    "    if game_id == '':\n",
    "        game_id = '%'\n",
    "    if player_id == '':\n",
    "        player_id = '%'\n",
    "        \n",
    "    sql = \"select distinct player_id from aggregated_game_data_t \\\n",
    "           where player_id <> (select id from players_t where name like 'ball')\\\n",
    "           and player_id like :player_id\\\n",
    "           and game_id like :game_id\"\n",
    "    \n",
    "    df = pd.read_sql(sql,params={'game_id':game_id,'player_id':player_id},con=engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dataframes for players\n",
    "#df_1M = Get_aggregated_data_full_game('','1052','1M')\n",
    "df_5M = Get_aggregated_data_full_game('','1052','5M')\n",
    "#df_15M = Get_aggregated_data_full_game('','1052','15M')\n",
    "players = Get_players('','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test and trainingsets\n",
    "#5M test/training set\n",
    "X = df_5M.iloc[:, 3:6].values\n",
    "y = df_5M.iloc[:, 6].values\n",
    "\n",
    "#15M test/trainingset\n",
    "#X= df_5M.iloc[:, 3:6].values\n",
    "#y=df_5M.iloc[:, 6].values\n",
    "\n",
    "#test scaling or not \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(np_scaled)\n",
    "\n",
    "X_train_s,X_test_s,y_train,y_test=train_test_split(X_scaled,y, test_size=0.3, random_state=10)    \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "  'svm__kernel': ['linear', 'rbf'],\n",
    "  'svm__C': 10 ** (uniform().rvs(100) * 5 - 2),  # error cost, exponentieel tussen de 0.001 and 1000\n",
    "  'svm__gamma': 10 ** (uniform().rvs(100) * 5 - 2) # smoothness, exponentieel tussen de 0.001 and 1000\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "  'rf__n_estimators': np.round(10 ** (uniform().rvs(1000) * 3)).astype(int), # aantal bomen\n",
    "  'rf__max_depth': np.round(10 ** (uniform().rvs(1000) * 3)).astype(int), # maximale lengte van een boom\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "  'lr__C': np.logspace(-4, 4, 20), #error \n",
    "  'lr__solver':['liblinear']\n",
    "}\n",
    "\n",
    "lightgbm_params = {\n",
    "  'gbm__n_estimators': np.round(10 ** (uniform().rvs(1000) * 3)).astype(int), # aantal bomen\n",
    "  'gbm__max_depth': np.round(10 ** (uniform().rvs(1000) * 3)).astype(int), # maximale lengte van een boom\n",
    "}\n",
    "\n",
    "classifiers = [\n",
    "  ('svm', SVC(), svm_params),\n",
    "  ('rf', RandomForestClassifier(), rf_params),\n",
    "  ('lr', LogisticRegression(), lr_params),\n",
    "  ('gbm',  LGBMClassifier(), lightgbm_params),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for name, classifier, params in classifiers:\n",
    "  steps = []\n",
    "  steps.append((name, classifier))\n",
    "\n",
    "  model = Pipeline(steps=steps) \n",
    "\n",
    "  tuned_model = RandomizedSearchCV(model, cv=4, n_iter=3, n_jobs=2, param_distributions=params, scoring='accuracy')\n",
    "  models.append((name, tuned_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________________________\n",
      "Hyperparameters voor model svm\n",
      "svm__kernel                    linear\n",
      "svm__gamma                     0.1357657631955643\n",
      "svm__C                         0.5311317448242108\n",
      "\n",
      "______________________________________________________________________\n",
      "Hyperparameters voor model rf\n",
      "rf__n_estimators               14\n",
      "rf__max_depth                  21\n",
      "\n",
      "______________________________________________________________________\n",
      "Hyperparameters voor model lr\n",
      "lr__solver                     liblinear\n",
      "lr__C                          0.23357214690901212\n",
      "\n",
      "______________________________________________________________________\n",
      "Hyperparameters voor model gbm\n",
      "gbm__n_estimators              25\n",
      "gbm__max_depth                 130\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "  print()\n",
    "  print('_' * 70)\n",
    "  print(f'Hyperparameters voor model {name}')\n",
    "  for param, value in model.best_params_.items():\n",
    "        print(f'{param:30s} {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wegschrijven van de Hyperparameters in een csv document\n",
    "import csv\n",
    "class CSVFile:\n",
    "    def __init__(self, doctitle):\n",
    "        self.doctitle = doctitle + \".csv\"\n",
    "        with open(doctitle, 'w+') as a:\n",
    "            writer = csv.writer(a)\n",
    "            writer.writerow([\"parameter\", \"value\"])\n",
    "            \n",
    "    def appendrow(self, parameter, waarde):\n",
    "        with open(self.doctitle, 'a+') as a:\n",
    "            writer = csv.writer(a)\n",
    "            writer.writerow([parameter, waarde])\n",
    "\n",
    "mycsv = CSVFile(\"parameters\")\n",
    "\n",
    "for name, model in models:\n",
    "    b = (f'Hyperparameters for model {name}')\n",
    "    mycsv.appendrow(b, ' ')\n",
    "    for param, value in model.best_params_.items():\n",
    "        mycsv.appendrow(param, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________________________________________________________\n",
      "Classification report voor model svm\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Distance reached       0.60      0.54      0.57        28\n",
      "Distance not reached       0.77      0.81      0.79        54\n",
      "\n",
      "            accuracy                           0.72        82\n",
      "           macro avg       0.69      0.68      0.68        82\n",
      "        weighted avg       0.71      0.72      0.72        82\n",
      "\n",
      "\n",
      "____________________________________________________________\n",
      "Classification report voor model rf\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Distance reached       0.79      0.79      0.79        28\n",
      "Distance not reached       0.89      0.89      0.89        54\n",
      "\n",
      "            accuracy                           0.85        82\n",
      "           macro avg       0.84      0.84      0.84        82\n",
      "        weighted avg       0.85      0.85      0.85        82\n",
      "\n",
      "\n",
      "____________________________________________________________\n",
      "Classification report voor model lr\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Distance reached       0.76      0.57      0.65        28\n",
      "Distance not reached       0.80      0.91      0.85        54\n",
      "\n",
      "            accuracy                           0.79        82\n",
      "           macro avg       0.78      0.74      0.75        82\n",
      "        weighted avg       0.79      0.79      0.78        82\n",
      "\n",
      "\n",
      "____________________________________________________________\n",
      "Classification report voor model gbm\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "    Distance reached       0.70      0.57      0.63        28\n",
      "Distance not reached       0.80      0.87      0.83        54\n",
      "\n",
      "            accuracy                           0.77        82\n",
      "           macro avg       0.75      0.72      0.73        82\n",
      "        weighted avg       0.76      0.77      0.76        82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "  print()\n",
    "  print('_' * 60)\n",
    "  print(f'Classification report voor model {name}')\n",
    "  \n",
    "  y_pred = model.predict(X_test)\n",
    "  print(classification_report(y_test, y_pred,target_names=['Distance reached', 'Distance not reached']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________________________________________________________\n",
      "Confusion matrix svm\n",
      "            predicted bad  predicted good\n",
      "actual bad             15              10\n",
      "actual good            13              44\n",
      "\n",
      "____________________________________________________________\n",
      "Confusion matrix rf\n",
      "            predicted bad  predicted good\n",
      "actual bad             22               6\n",
      "actual good             6              48\n",
      "\n",
      "____________________________________________________________\n",
      "Confusion matrix lr\n",
      "            predicted bad  predicted good\n",
      "actual bad             16               5\n",
      "actual good            12              49\n",
      "\n",
      "____________________________________________________________\n",
      "Confusion matrix gbm\n",
      "            predicted bad  predicted good\n",
      "actual bad             16               7\n",
      "actual good            12              47\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "  print()\n",
    "  print('_' * 60)\n",
    "  print(f'Confusion matrix {name}')\n",
    "  \n",
    "  y_pred = model.predict(X_test)\n",
    "  (tn, fp), (fn, tp) = confusion_matrix(y_test, y_pred)\n",
    "  print(f'            predicted bad  predicted good')\n",
    "  print(f'actual bad   {tn:12d}  {fn:14d}')\n",
    "  print(f'actual good  {fp:12d}  {tp:14d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models:\n",
    "     if name == 'lr':\n",
    "        lr_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what would be the prediction for a player who was not present during the whole game\n",
    "#df_1M_nf = Get_aggregated_data_not_full_game('','962','1M')\n",
    "#df_5M_nf = Get_aggregated_data_not_full_game('','962','5M')\n",
    "df_15M_nf = Get_aggregated_data_not_full_game('','962','15M')\n",
    "X_nf = df_15M_nf.dropna()\n",
    "X_nf = X_nf.iloc[:, 3:6].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_nf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nf_df= pd.DataFrame (X_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nf_df['y_pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nf_df.to_csv(path_or_buf = 'X_nf_15M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talko\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: 0.710526 (0.092667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talko\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: 0.800000 (0.045883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talko\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.752632 (0.059079)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talko\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm: 0.789474 (0.055200)\n"
     ]
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=7)\n",
    "    if name in ('SVC','SGD','KNN','NN'):\n",
    "        cv_results = model_selection.cross_val_score(model, X_train_s, y_train, cv=kfold, scoring=scoring)\n",
    "    else:\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ax = sns.boxplot(data=results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5M = Get_aggregated_data_full_game('','1052','5M')\n",
    "X = df_5M.iloc[:, 3:6].values\n",
    "y = df_5M.iloc[:, 6].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 408, 0: 223})\n",
      "Resampled dataset shape Counter({1: 408, 0: 408})\n"
     ]
    }
   ],
   "source": [
    "#resample skewed dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "sm = SMOTE(random_state = 42)\n",
    "#sm = SVMSMOTE(random_state = 42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "#splitsen van de data 25% test- & 75% trainingsdata resample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.25, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitsen van de data 25% test- & 75% trainingsdata no resample\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schale\n",
    "#sc = MinMaxScaler(feature_range=(0, 1))\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(X_train)\n",
    "x_test = sc.transform(X_test)\n",
    "\n",
    "#Our input has xtrain.shape[0] samples, where each sample consist of 1 time-step \n",
    "#and each time-step consists of x_train.shape[1] features. \n",
    "#The following reshapes the input.\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],1,x_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "473/473 [==============================] - 4s 9ms/step - loss: 0.4920\n",
      "Epoch 2/100\n",
      "473/473 [==============================] - 0s 971us/step - loss: 0.2291\n",
      "Epoch 3/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.2183\n",
      "Epoch 4/100\n",
      "473/473 [==============================] - 0s 995us/step - loss: 0.2145\n",
      "Epoch 5/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.2156\n",
      "Epoch 6/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.2175\n",
      "Epoch 7/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.2064\n",
      "Epoch 8/100\n",
      "473/473 [==============================] - 0s 998us/step - loss: 0.1997\n",
      "Epoch 9/100\n",
      "473/473 [==============================] - 0s 991us/step - loss: 0.2015\n",
      "Epoch 10/100\n",
      "473/473 [==============================] - 0s 1000us/step - loss: 0.1897\n",
      "Epoch 11/100\n",
      "473/473 [==============================] - 0s 995us/step - loss: 0.1828\n",
      "Epoch 12/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1763\n",
      "Epoch 13/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1658\n",
      "Epoch 14/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1597\n",
      "Epoch 15/100\n",
      "473/473 [==============================] - 0s 999us/step - loss: 0.1635\n",
      "Epoch 16/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1600\n",
      "Epoch 17/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1585\n",
      "Epoch 18/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1590\n",
      "Epoch 19/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1541\n",
      "Epoch 20/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1549\n",
      "Epoch 21/100\n",
      "473/473 [==============================] - 0s 994us/step - loss: 0.1496\n",
      "Epoch 22/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1593\n",
      "Epoch 23/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1544\n",
      "Epoch 24/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1511\n",
      "Epoch 25/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1552\n",
      "Epoch 26/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1444\n",
      "Epoch 27/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1486\n",
      "Epoch 28/100\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 0.1503\n",
      "Epoch 29/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1490\n",
      "Epoch 30/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1471\n",
      "Epoch 31/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1446\n",
      "Epoch 32/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1433\n",
      "Epoch 33/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1424\n",
      "Epoch 34/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1467\n",
      "Epoch 35/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1474\n",
      "Epoch 36/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1467\n",
      "Epoch 37/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1446\n",
      "Epoch 38/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1426\n",
      "Epoch 39/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1422\n",
      "Epoch 40/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1436\n",
      "Epoch 41/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1434\n",
      "Epoch 42/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1496\n",
      "Epoch 43/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1464\n",
      "Epoch 44/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1430\n",
      "Epoch 45/100\n",
      "473/473 [==============================] - 0s 1000us/step - loss: 0.1504\n",
      "Epoch 46/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1463\n",
      "Epoch 47/100\n",
      "473/473 [==============================] - 0s 999us/step - loss: 0.1434\n",
      "Epoch 48/100\n",
      "473/473 [==============================] - 0s 977us/step - loss: 0.1388\n",
      "Epoch 49/100\n",
      "473/473 [==============================] - 0s 992us/step - loss: 0.1454\n",
      "Epoch 50/100\n",
      "473/473 [==============================] - 0s 981us/step - loss: 0.1473\n",
      "Epoch 51/100\n",
      "473/473 [==============================] - 0s 991us/step - loss: 0.1430\n",
      "Epoch 52/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1441\n",
      "Epoch 53/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1393\n",
      "Epoch 54/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1408\n",
      "Epoch 55/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1452\n",
      "Epoch 56/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1408\n",
      "Epoch 57/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1421\n",
      "Epoch 58/100\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 0.1388\n",
      "Epoch 59/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1429\n",
      "Epoch 60/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1430\n",
      "Epoch 61/100\n",
      "473/473 [==============================] - 0s 996us/step - loss: 0.1384\n",
      "Epoch 62/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1359\n",
      "Epoch 63/100\n",
      "473/473 [==============================] - 0s 996us/step - loss: 0.1361\n",
      "Epoch 64/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1383\n",
      "Epoch 65/100\n",
      "473/473 [==============================] - 0s 996us/step - loss: 0.1331\n",
      "Epoch 66/100\n",
      "473/473 [==============================] - 0s 960us/step - loss: 0.1394\n",
      "Epoch 67/100\n",
      "473/473 [==============================] - 0s 961us/step - loss: 0.1358\n",
      "Epoch 68/100\n",
      "473/473 [==============================] - 0s 981us/step - loss: 0.1322\n",
      "Epoch 69/100\n",
      "473/473 [==============================] - 0s 985us/step - loss: 0.1405\n",
      "Epoch 70/100\n",
      "473/473 [==============================] - 0s 996us/step - loss: 0.1339\n",
      "Epoch 71/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1320\n",
      "Epoch 72/100\n",
      "473/473 [==============================] - 0s 996us/step - loss: 0.1340\n",
      "Epoch 73/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1298\n",
      "Epoch 74/100\n",
      "473/473 [==============================] - 0s 999us/step - loss: 0.1346\n",
      "Epoch 75/100\n",
      "473/473 [==============================] - 0s 986us/step - loss: 0.1301\n",
      "Epoch 76/100\n",
      "473/473 [==============================] - 0s 989us/step - loss: 0.1314\n",
      "Epoch 77/100\n",
      "473/473 [==============================] - 0s 995us/step - loss: 0.1283\n",
      "Epoch 78/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1320\n",
      "Epoch 79/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1315\n",
      "Epoch 80/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1283\n",
      "Epoch 81/100\n",
      "473/473 [==============================] - 0s 978us/step - loss: 0.1331\n",
      "Epoch 82/100\n",
      "473/473 [==============================] - 0s 960us/step - loss: 0.1267\n",
      "Epoch 83/100\n",
      "473/473 [==============================] - 0s 991us/step - loss: 0.1337\n",
      "Epoch 84/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1267\n",
      "Epoch 85/100\n",
      "473/473 [==============================] - 0s 973us/step - loss: 0.1279\n",
      "Epoch 86/100\n",
      "473/473 [==============================] - 0s 991us/step - loss: 0.1275\n",
      "Epoch 87/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1296\n",
      "Epoch 88/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1265\n",
      "Epoch 89/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1262\n",
      "Epoch 90/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1292\n",
      "Epoch 91/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1285\n",
      "Epoch 92/100\n",
      "473/473 [==============================] - 0s 982us/step - loss: 0.1283\n",
      "Epoch 93/100\n",
      "473/473 [==============================] - 0s 989us/step - loss: 0.1317\n",
      "Epoch 94/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1283\n",
      "Epoch 95/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1284\n",
      "Epoch 96/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1296\n",
      "Epoch 97/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1289\n",
      "Epoch 98/100\n",
      "473/473 [==============================] - 0s 1ms/step - loss: 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "473/473 [==============================] - 0s 989us/step - loss: 0.1257\n",
      "Epoch 100/100\n",
      "473/473 [==============================] - 0s 989us/step - loss: 0.1247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x287120b1f98>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (1,X_train.shape[1])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs = 100, batch_size = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "323/323 [==============================] - 5s 14ms/step - loss: 0.5170\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2832\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2333\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2325\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2267\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2238\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2272\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2234\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2244\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2235\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2247\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2233\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2263\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2229\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2226\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2230\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2229\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2252\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2262\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2273\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2228\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2236\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2221\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2242\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2214\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2212\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2219\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2212\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2237\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2202\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2231\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2205A: 0s - l\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2211\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2203\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2209\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2202\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2207\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2229\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2228\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2183\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2202\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2206\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2185\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2209\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2196\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 1s 3ms/step - loss: 0.2175\n",
      "Epoch 47/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2192\n",
      "Epoch 48/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2167\n",
      "Epoch 49/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2178\n",
      "Epoch 50/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2187\n",
      "Epoch 51/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2185\n",
      "Epoch 52/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2182\n",
      "Epoch 53/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2193\n",
      "Epoch 54/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2220\n",
      "Epoch 55/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2162\n",
      "Epoch 56/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2196\n",
      "Epoch 57/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2164\n",
      "Epoch 58/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2181\n",
      "Epoch 59/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2149\n",
      "Epoch 60/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2196\n",
      "Epoch 61/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2152\n",
      "Epoch 62/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2157\n",
      "Epoch 63/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2191\n",
      "Epoch 64/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2162\n",
      "Epoch 65/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2160\n",
      "Epoch 66/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2171\n",
      "Epoch 67/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2154\n",
      "Epoch 68/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2169\n",
      "Epoch 69/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2150\n",
      "Epoch 70/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2150\n",
      "Epoch 71/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2147\n",
      "Epoch 72/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2155\n",
      "Epoch 73/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2162\n",
      "Epoch 74/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2146\n",
      "Epoch 75/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2132\n",
      "Epoch 76/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2155\n",
      "Epoch 77/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2173\n",
      "Epoch 78/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2154\n",
      "Epoch 79/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2183\n",
      "Epoch 80/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2145\n",
      "Epoch 81/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2157\n",
      "Epoch 82/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2133\n",
      "Epoch 83/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2125\n",
      "Epoch 84/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2152\n",
      "Epoch 85/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2129\n",
      "Epoch 86/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2130\n",
      "Epoch 87/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2131\n",
      "Epoch 88/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2126\n",
      "Epoch 89/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2164\n",
      "Epoch 90/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2119\n",
      "Epoch 91/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2114\n",
      "Epoch 92/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2111\n",
      "Epoch 93/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2149\n",
      "Epoch 94/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2112\n",
      "Epoch 95/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2106\n",
      "Epoch 96/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2112\n",
      "Epoch 97/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2096\n",
      "Epoch 98/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2085\n",
      "Epoch 99/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2117\n",
      "Epoch 100/100\n",
      "323/323 [==============================] - 1s 2ms/step - loss: 0.2084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x287037c3d68>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Stacked lstm\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(1,X_train.shape[1])))\n",
    "regressor.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "regressor.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "regressor.add(LSTM(25, activation='relu'))\n",
    "regressor.add(Dense(20, activation='relu'))\n",
    "regressor.add(Dense(10, activation='relu'))\n",
    "regressor.add(Dense(1))\n",
    "regressor.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "regressor.fit(x_train, y_train, epochs = 100, batch_size = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314 samples, validate on 79 samples\n",
      "Epoch 1/1000\n",
      "314/314 [==============================] - 4s 12ms/step - loss: 0.4635 - val_loss: 0.3227\n",
      "Epoch 2/1000\n",
      "314/314 [==============================] - 0s 424us/step - loss: 0.3899 - val_loss: 0.2793\n",
      "Epoch 3/1000\n",
      "314/314 [==============================] - 0s 406us/step - loss: 0.3376 - val_loss: 0.2521\n",
      "Epoch 4/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2958 - val_loss: 0.2411\n",
      "Epoch 5/1000\n",
      "314/314 [==============================] - 0s 424us/step - loss: 0.2777 - val_loss: 0.2393\n",
      "Epoch 6/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.2652 - val_loss: 0.2400\n",
      "Epoch 7/1000\n",
      "314/314 [==============================] - 0s 423us/step - loss: 0.2574 - val_loss: 0.2409\n",
      "Epoch 8/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.2494 - val_loss: 0.2425\n",
      "Epoch 9/1000\n",
      "314/314 [==============================] - 0s 446us/step - loss: 0.2443 - val_loss: 0.2443\n",
      "Epoch 10/1000\n",
      "314/314 [==============================] - 0s 491us/step - loss: 0.2428 - val_loss: 0.2450\n",
      "Epoch 11/1000\n",
      "314/314 [==============================] - 0s 442us/step - loss: 0.2397 - val_loss: 0.2462\n",
      "Epoch 12/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.2377 - val_loss: 0.2480\n",
      "Epoch 13/1000\n",
      "314/314 [==============================] - 0s 423us/step - loss: 0.2344 - val_loss: 0.2508\n",
      "Epoch 14/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.2306 - val_loss: 0.2541\n",
      "Epoch 15/1000\n",
      "314/314 [==============================] - 0s 437us/step - loss: 0.2284 - val_loss: 0.2550\n",
      "Epoch 16/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.2332 - val_loss: 0.2574\n",
      "Epoch 17/1000\n",
      "314/314 [==============================] - 0s 447us/step - loss: 0.2297 - val_loss: 0.2567\n",
      "Epoch 18/1000\n",
      "314/314 [==============================] - 0s 432us/step - loss: 0.2308 - val_loss: 0.2569\n",
      "Epoch 19/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.2284 - val_loss: 0.2581\n",
      "Epoch 20/1000\n",
      "314/314 [==============================] - 0s 460us/step - loss: 0.2229 - val_loss: 0.2586\n",
      "Epoch 21/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.2246 - val_loss: 0.2573\n",
      "Epoch 22/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.2287 - val_loss: 0.2578\n",
      "Epoch 23/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.2280 - val_loss: 0.2586\n",
      "Epoch 24/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.2254 - val_loss: 0.2588\n",
      "Epoch 25/1000\n",
      "314/314 [==============================] - 0s 443us/step - loss: 0.2267 - val_loss: 0.2617\n",
      "Epoch 26/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.2279 - val_loss: 0.2597\n",
      "Epoch 27/1000\n",
      "314/314 [==============================] - 0s 426us/step - loss: 0.2247 - val_loss: 0.2616\n",
      "Epoch 28/1000\n",
      "314/314 [==============================] - 0s 430us/step - loss: 0.2241 - val_loss: 0.2603\n",
      "Epoch 29/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.2212 - val_loss: 0.2627\n",
      "Epoch 30/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.2237 - val_loss: 0.2646\n",
      "Epoch 31/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.2264 - val_loss: 0.2607\n",
      "Epoch 32/1000\n",
      "314/314 [==============================] - 0s 484us/step - loss: 0.2232 - val_loss: 0.2604\n",
      "Epoch 33/1000\n",
      "314/314 [==============================] - 0s 486us/step - loss: 0.2224 - val_loss: 0.2639\n",
      "Epoch 34/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.2213 - val_loss: 0.2628\n",
      "Epoch 35/1000\n",
      "314/314 [==============================] - 0s 408us/step - loss: 0.2229 - val_loss: 0.2606\n",
      "Epoch 36/1000\n",
      "314/314 [==============================] - 0s 428us/step - loss: 0.2223 - val_loss: 0.2620\n",
      "Epoch 37/1000\n",
      "314/314 [==============================] - 0s 396us/step - loss: 0.2211 - val_loss: 0.2621\n",
      "Epoch 38/1000\n",
      "314/314 [==============================] - 0s 470us/step - loss: 0.2236 - val_loss: 0.2613\n",
      "Epoch 39/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.2238 - val_loss: 0.2621\n",
      "Epoch 40/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.2257 - val_loss: 0.2625\n",
      "Epoch 41/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.2211 - val_loss: 0.2593\n",
      "Epoch 42/1000\n",
      "314/314 [==============================] - 0s 477us/step - loss: 0.2236 - val_loss: 0.2622\n",
      "Epoch 43/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.2207 - val_loss: 0.2635\n",
      "Epoch 44/1000\n",
      "314/314 [==============================] - 0s 416us/step - loss: 0.2219 - val_loss: 0.2612\n",
      "Epoch 45/1000\n",
      "314/314 [==============================] - 0s 465us/step - loss: 0.2210 - val_loss: 0.2614\n",
      "Epoch 46/1000\n",
      "314/314 [==============================] - 0s 467us/step - loss: 0.2199 - val_loss: 0.2629\n",
      "Epoch 47/1000\n",
      "314/314 [==============================] - 0s 444us/step - loss: 0.2208 - val_loss: 0.2628\n",
      "Epoch 48/1000\n",
      "314/314 [==============================] - 0s 430us/step - loss: 0.2231 - val_loss: 0.2603\n",
      "Epoch 49/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.2200 - val_loss: 0.2597\n",
      "Epoch 50/1000\n",
      "314/314 [==============================] - 0s 465us/step - loss: 0.2224 - val_loss: 0.2649\n",
      "Epoch 51/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.2211 - val_loss: 0.2607\n",
      "Epoch 52/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2191 - val_loss: 0.2638\n",
      "Epoch 53/1000\n",
      "314/314 [==============================] - 0s 443us/step - loss: 0.2234 - val_loss: 0.2638\n",
      "Epoch 54/1000\n",
      "314/314 [==============================] - 0s 443us/step - loss: 0.2245 - val_loss: 0.2609\n",
      "Epoch 55/1000\n",
      "314/314 [==============================] - 0s 454us/step - loss: 0.2211 - val_loss: 0.2614\n",
      "Epoch 56/1000\n",
      "314/314 [==============================] - 0s 453us/step - loss: 0.2234 - val_loss: 0.2612\n",
      "Epoch 57/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.2185 - val_loss: 0.2614\n",
      "Epoch 58/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.2166 - val_loss: 0.2648\n",
      "Epoch 59/1000\n",
      "314/314 [==============================] - 0s 416us/step - loss: 0.2207 - val_loss: 0.2660\n",
      "Epoch 60/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.2161 - val_loss: 0.2665\n",
      "Epoch 61/1000\n",
      "314/314 [==============================] - 0s 439us/step - loss: 0.2223 - val_loss: 0.2648\n",
      "Epoch 62/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.2176 - val_loss: 0.2631\n",
      "Epoch 63/1000\n",
      "314/314 [==============================] - 0s 461us/step - loss: 0.2181 - val_loss: 0.2608\n",
      "Epoch 64/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.2177 - val_loss: 0.2610\n",
      "Epoch 65/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2189 - val_loss: 0.2654\n",
      "Epoch 66/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.2175 - val_loss: 0.2629\n",
      "Epoch 67/1000\n",
      "314/314 [==============================] - 0s 432us/step - loss: 0.2180 - val_loss: 0.2659\n",
      "Epoch 68/1000\n",
      "314/314 [==============================] - 0s 428us/step - loss: 0.2157 - val_loss: 0.2664\n",
      "Epoch 69/1000\n",
      "314/314 [==============================] - 0s 460us/step - loss: 0.2148 - val_loss: 0.2628\n",
      "Epoch 70/1000\n",
      "314/314 [==============================] - 0s 426us/step - loss: 0.2187 - val_loss: 0.2638\n",
      "Epoch 71/1000\n",
      "314/314 [==============================] - 0s 527us/step - loss: 0.2198 - val_loss: 0.2640\n",
      "Epoch 72/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.2194 - val_loss: 0.2623\n",
      "Epoch 73/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2220 - val_loss: 0.2641\n",
      "Epoch 74/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.2224 - val_loss: 0.2655\n",
      "Epoch 75/1000\n",
      "314/314 [==============================] - 0s 469us/step - loss: 0.2184 - val_loss: 0.2614\n",
      "Epoch 76/1000\n",
      "314/314 [==============================] - 0s 425us/step - loss: 0.2172 - val_loss: 0.2662\n",
      "Epoch 77/1000\n",
      "314/314 [==============================] - 0s 473us/step - loss: 0.2173 - val_loss: 0.2675\n",
      "Epoch 78/1000\n",
      "314/314 [==============================] - 0s 460us/step - loss: 0.2166 - val_loss: 0.2663\n",
      "Epoch 79/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.2179 - val_loss: 0.2625\n",
      "Epoch 80/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2197 - val_loss: 0.2631\n",
      "Epoch 81/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2160 - val_loss: 0.2662\n",
      "Epoch 82/1000\n",
      "314/314 [==============================] - 0s 429us/step - loss: 0.2165 - val_loss: 0.2696\n",
      "Epoch 83/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2189 - val_loss: 0.2632\n",
      "Epoch 84/1000\n",
      "314/314 [==============================] - 0s 394us/step - loss: 0.2182 - val_loss: 0.2625\n",
      "Epoch 85/1000\n",
      "314/314 [==============================] - 0s 364us/step - loss: 0.2195 - val_loss: 0.2661\n",
      "Epoch 86/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2189 - val_loss: 0.2705\n",
      "Epoch 87/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2161 - val_loss: 0.2683\n",
      "Epoch 88/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.2163 - val_loss: 0.2646\n",
      "Epoch 89/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2189 - val_loss: 0.2644\n",
      "Epoch 90/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.2142 - val_loss: 0.2673\n",
      "Epoch 91/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.2146 - val_loss: 0.2689\n",
      "Epoch 92/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2167 - val_loss: 0.2705\n",
      "Epoch 93/1000\n",
      "314/314 [==============================] - 0s 425us/step - loss: 0.2152 - val_loss: 0.2652\n",
      "Epoch 94/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.2145 - val_loss: 0.2682\n",
      "Epoch 95/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.2198 - val_loss: 0.2713\n",
      "Epoch 96/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.2183 - val_loss: 0.2671\n",
      "Epoch 97/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.2170 - val_loss: 0.2656\n",
      "Epoch 98/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.2150 - val_loss: 0.2664\n",
      "Epoch 99/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.2141 - val_loss: 0.2683\n",
      "Epoch 100/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2110 - val_loss: 0.2673\n",
      "Epoch 101/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2119 - val_loss: 0.2671\n",
      "Epoch 102/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2156 - val_loss: 0.2704\n",
      "Epoch 103/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.2177 - val_loss: 0.2722\n",
      "Epoch 104/1000\n",
      "314/314 [==============================] - 0s 492us/step - loss: 0.2123 - val_loss: 0.2669\n",
      "Epoch 105/1000\n",
      "314/314 [==============================] - 0s 399us/step - loss: 0.2151 - val_loss: 0.2654\n",
      "Epoch 106/1000\n",
      "314/314 [==============================] - 0s 367us/step - loss: 0.2159 - val_loss: 0.2662\n",
      "Epoch 107/1000\n",
      "314/314 [==============================] - 0s 412us/step - loss: 0.2130 - val_loss: 0.2712\n",
      "Epoch 108/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.2161 - val_loss: 0.2684\n",
      "Epoch 109/1000\n",
      "314/314 [==============================] - 0s 397us/step - loss: 0.2128 - val_loss: 0.2669\n",
      "Epoch 110/1000\n",
      "314/314 [==============================] - 0s 393us/step - loss: 0.2139 - val_loss: 0.2675\n",
      "Epoch 111/1000\n",
      "314/314 [==============================] - 0s 367us/step - loss: 0.2119 - val_loss: 0.2711\n",
      "Epoch 112/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2123 - val_loss: 0.2779\n",
      "Epoch 113/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2151 - val_loss: 0.2725\n",
      "Epoch 114/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2129 - val_loss: 0.2693\n",
      "Epoch 115/1000\n",
      "314/314 [==============================] - 0s 413us/step - loss: 0.2152 - val_loss: 0.2692\n",
      "Epoch 116/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2125 - val_loss: 0.2681\n",
      "Epoch 117/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.2103 - val_loss: 0.2701\n",
      "Epoch 118/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.2097 - val_loss: 0.2714\n",
      "Epoch 119/1000\n",
      "314/314 [==============================] - 0s 472us/step - loss: 0.2110 - val_loss: 0.2737\n",
      "Epoch 120/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.2108 - val_loss: 0.2716\n",
      "Epoch 121/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.2124 - val_loss: 0.2735\n",
      "Epoch 122/1000\n",
      "314/314 [==============================] - 0s 410us/step - loss: 0.2131 - val_loss: 0.2720\n",
      "Epoch 123/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2160 - val_loss: 0.2715\n",
      "Epoch 124/1000\n",
      "314/314 [==============================] - 0s 438us/step - loss: 0.2113 - val_loss: 0.2709\n",
      "Epoch 125/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.2121 - val_loss: 0.2716\n",
      "Epoch 126/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.2137 - val_loss: 0.2708\n",
      "Epoch 127/1000\n",
      "314/314 [==============================] - 0s 442us/step - loss: 0.2121 - val_loss: 0.2688\n",
      "Epoch 128/1000\n",
      "314/314 [==============================] - 0s 396us/step - loss: 0.2135 - val_loss: 0.2671\n",
      "Epoch 129/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2097 - val_loss: 0.2725\n",
      "Epoch 130/1000\n",
      "314/314 [==============================] - 0s 365us/step - loss: 0.2165 - val_loss: 0.2705\n",
      "Epoch 131/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2119 - val_loss: 0.2752\n",
      "Epoch 132/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2153 - val_loss: 0.2737\n",
      "Epoch 133/1000\n",
      "314/314 [==============================] - 0s 435us/step - loss: 0.2083 - val_loss: 0.2717\n",
      "Epoch 134/1000\n",
      "314/314 [==============================] - 0s 422us/step - loss: 0.2102 - val_loss: 0.2747\n",
      "Epoch 135/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.2156 - val_loss: 0.2750\n",
      "Epoch 136/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.2080 - val_loss: 0.2723\n",
      "Epoch 137/1000\n",
      "314/314 [==============================] - 0s 436us/step - loss: 0.2103 - val_loss: 0.2703\n",
      "Epoch 138/1000\n",
      "314/314 [==============================] - 0s 443us/step - loss: 0.2075 - val_loss: 0.2728\n",
      "Epoch 139/1000\n",
      "314/314 [==============================] - 0s 583us/step - loss: 0.2095 - val_loss: 0.2738\n",
      "Epoch 140/1000\n",
      "314/314 [==============================] - 0s 562us/step - loss: 0.2105 - val_loss: 0.2728\n",
      "Epoch 141/1000\n",
      "314/314 [==============================] - 0s 557us/step - loss: 0.2088 - val_loss: 0.2782\n",
      "Epoch 142/1000\n",
      "314/314 [==============================] - 0s 521us/step - loss: 0.2124 - val_loss: 0.2739\n",
      "Epoch 143/1000\n",
      "314/314 [==============================] - 0s 535us/step - loss: 0.2113 - val_loss: 0.2721\n",
      "Epoch 144/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.209 - 0s 554us/step - loss: 0.2123 - val_loss: 0.2710\n",
      "Epoch 145/1000\n",
      "314/314 [==============================] - 0s 640us/step - loss: 0.2104 - val_loss: 0.2780\n",
      "Epoch 146/1000\n",
      "314/314 [==============================] - 0s 623us/step - loss: 0.2094 - val_loss: 0.2750\n",
      "Epoch 147/1000\n",
      "314/314 [==============================] - 0s 507us/step - loss: 0.2093 - val_loss: 0.2760\n",
      "Epoch 148/1000\n",
      "314/314 [==============================] - 0s 446us/step - loss: 0.2093 - val_loss: 0.2734\n",
      "Epoch 149/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.2108 - val_loss: 0.2711\n",
      "Epoch 150/1000\n",
      "314/314 [==============================] - 0s 542us/step - loss: 0.2109 - val_loss: 0.2719\n",
      "Epoch 151/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.2088 - val_loss: 0.2723\n",
      "Epoch 152/1000\n",
      "314/314 [==============================] - 0s 423us/step - loss: 0.2089 - val_loss: 0.2759\n",
      "Epoch 153/1000\n",
      "314/314 [==============================] - 0s 536us/step - loss: 0.2104 - val_loss: 0.2757\n",
      "Epoch 154/1000\n",
      "314/314 [==============================] - 0s 574us/step - loss: 0.2101 - val_loss: 0.2741\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 466us/step - loss: 0.2113 - val_loss: 0.2744\n",
      "Epoch 156/1000\n",
      "314/314 [==============================] - 0s 452us/step - loss: 0.2107 - val_loss: 0.2745\n",
      "Epoch 157/1000\n",
      "314/314 [==============================] - 0s 399us/step - loss: 0.2119 - val_loss: 0.2749\n",
      "Epoch 158/1000\n",
      "314/314 [==============================] - 0s 615us/step - loss: 0.2112 - val_loss: 0.2775\n",
      "Epoch 159/1000\n",
      "314/314 [==============================] - 0s 719us/step - loss: 0.2115 - val_loss: 0.2779\n",
      "Epoch 160/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.2081 - val_loss: 0.2781\n",
      "Epoch 161/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.2119 - val_loss: 0.2738\n",
      "Epoch 162/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.2088 - val_loss: 0.2776\n",
      "Epoch 163/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.2103 - val_loss: 0.2783\n",
      "Epoch 164/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.2120 - val_loss: 0.2739\n",
      "Epoch 165/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2098 - val_loss: 0.2799\n",
      "Epoch 166/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2090 - val_loss: 0.2771\n",
      "Epoch 167/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.2070 - val_loss: 0.2757\n",
      "Epoch 168/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.2093 - val_loss: 0.2740\n",
      "Epoch 169/1000\n",
      "314/314 [==============================] - 0s 474us/step - loss: 0.2073 - val_loss: 0.2741\n",
      "Epoch 170/1000\n",
      "314/314 [==============================] - 0s 479us/step - loss: 0.2090 - val_loss: 0.2768\n",
      "Epoch 171/1000\n",
      "314/314 [==============================] - 0s 502us/step - loss: 0.2093 - val_loss: 0.2740\n",
      "Epoch 172/1000\n",
      "314/314 [==============================] - 0s 489us/step - loss: 0.2100 - val_loss: 0.2727\n",
      "Epoch 173/1000\n",
      "314/314 [==============================] - 0s 712us/step - loss: 0.2136 - val_loss: 0.2743\n",
      "Epoch 174/1000\n",
      "314/314 [==============================] - 0s 547us/step - loss: 0.2159 - val_loss: 0.2757\n",
      "Epoch 175/1000\n",
      "314/314 [==============================] - 0s 426us/step - loss: 0.2113 - val_loss: 0.2732\n",
      "Epoch 176/1000\n",
      "314/314 [==============================] - 0s 430us/step - loss: 0.2118 - val_loss: 0.2732\n",
      "Epoch 177/1000\n",
      "314/314 [==============================] - 0s 492us/step - loss: 0.2111 - val_loss: 0.2762\n",
      "Epoch 178/1000\n",
      "314/314 [==============================] - 0s 630us/step - loss: 0.2088 - val_loss: 0.2718\n",
      "Epoch 179/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.2080 - val_loss: 0.2754\n",
      "Epoch 180/1000\n",
      "314/314 [==============================] - 0s 452us/step - loss: 0.2112 - val_loss: 0.2851\n",
      "Epoch 181/1000\n",
      "314/314 [==============================] - 0s 440us/step - loss: 0.2028 - val_loss: 0.2773\n",
      "Epoch 182/1000\n",
      "314/314 [==============================] - 0s 459us/step - loss: 0.2092 - val_loss: 0.2749\n",
      "Epoch 183/1000\n",
      "314/314 [==============================] - 0s 456us/step - loss: 0.2111 - val_loss: 0.2747\n",
      "Epoch 184/1000\n",
      "314/314 [==============================] - 0s 454us/step - loss: 0.2083 - val_loss: 0.2719\n",
      "Epoch 185/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2077 - val_loss: 0.2749\n",
      "Epoch 186/1000\n",
      "314/314 [==============================] - 0s 419us/step - loss: 0.2085 - val_loss: 0.2804\n",
      "Epoch 187/1000\n",
      "314/314 [==============================] - 0s 427us/step - loss: 0.2047 - val_loss: 0.2769\n",
      "Epoch 188/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.2096 - val_loss: 0.2729\n",
      "Epoch 189/1000\n",
      "314/314 [==============================] - 0s 441us/step - loss: 0.2155 - val_loss: 0.2738\n",
      "Epoch 190/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.2084 - val_loss: 0.2819\n",
      "Epoch 191/1000\n",
      "314/314 [==============================] - 0s 442us/step - loss: 0.2090 - val_loss: 0.2826\n",
      "Epoch 192/1000\n",
      "314/314 [==============================] - 0s 465us/step - loss: 0.2098 - val_loss: 0.2759\n",
      "Epoch 193/1000\n",
      "314/314 [==============================] - 0s 426us/step - loss: 0.2146 - val_loss: 0.2745\n",
      "Epoch 194/1000\n",
      "314/314 [==============================] - 0s 466us/step - loss: 0.2041 - val_loss: 0.2790\n",
      "Epoch 195/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.2085 - val_loss: 0.2808\n",
      "Epoch 196/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.2048 - val_loss: 0.2791\n",
      "Epoch 197/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.2156 - val_loss: 0.2751\n",
      "Epoch 198/1000\n",
      "314/314 [==============================] - 0s 477us/step - loss: 0.2069 - val_loss: 0.2739\n",
      "Epoch 199/1000\n",
      "314/314 [==============================] - 0s 501us/step - loss: 0.2100 - val_loss: 0.2761\n",
      "Epoch 200/1000\n",
      "314/314 [==============================] - 0s 498us/step - loss: 0.2085 - val_loss: 0.2788\n",
      "Epoch 201/1000\n",
      "314/314 [==============================] - 0s 502us/step - loss: 0.2057 - val_loss: 0.2769\n",
      "Epoch 202/1000\n",
      "314/314 [==============================] - 0s 491us/step - loss: 0.2087 - val_loss: 0.2744\n",
      "Epoch 203/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.2034 - val_loss: 0.2756\n",
      "Epoch 204/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.2040 - val_loss: 0.2765\n",
      "Epoch 205/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.2078 - val_loss: 0.2752\n",
      "Epoch 206/1000\n",
      "314/314 [==============================] - 0s 470us/step - loss: 0.2059 - val_loss: 0.2810\n",
      "Epoch 207/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.2098 - val_loss: 0.2818\n",
      "Epoch 208/1000\n",
      "314/314 [==============================] - 0s 453us/step - loss: 0.2142 - val_loss: 0.2752\n",
      "Epoch 209/1000\n",
      "314/314 [==============================] - 0s 493us/step - loss: 0.2075 - val_loss: 0.2771\n",
      "Epoch 210/1000\n",
      "314/314 [==============================] - 0s 484us/step - loss: 0.2067 - val_loss: 0.2790\n",
      "Epoch 211/1000\n",
      "314/314 [==============================] - 0s 646us/step - loss: 0.2082 - val_loss: 0.2779\n",
      "Epoch 212/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2104 - val_loss: 0.2761\n",
      "Epoch 213/1000\n",
      "314/314 [==============================] - 0s 443us/step - loss: 0.2089 - val_loss: 0.2746\n",
      "Epoch 214/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.2112 - val_loss: 0.2756\n",
      "Epoch 215/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.2065 - val_loss: 0.2779\n",
      "Epoch 216/1000\n",
      "314/314 [==============================] - 0s 477us/step - loss: 0.2089 - val_loss: 0.2776\n",
      "Epoch 217/1000\n",
      "314/314 [==============================] - 0s 470us/step - loss: 0.2111 - val_loss: 0.2792\n",
      "Epoch 218/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.2081 - val_loss: 0.2733\n",
      "Epoch 219/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.2039 - val_loss: 0.2790\n",
      "Epoch 220/1000\n",
      "314/314 [==============================] - 0s 470us/step - loss: 0.2085 - val_loss: 0.2739\n",
      "Epoch 221/1000\n",
      "314/314 [==============================] - 0s 485us/step - loss: 0.2038 - val_loss: 0.2751\n",
      "Epoch 222/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.2044 - val_loss: 0.2746\n",
      "Epoch 223/1000\n",
      "314/314 [==============================] - 0s 474us/step - loss: 0.2056 - val_loss: 0.2761\n",
      "Epoch 224/1000\n",
      "314/314 [==============================] - 0s 507us/step - loss: 0.2082 - val_loss: 0.2759\n",
      "Epoch 225/1000\n",
      "314/314 [==============================] - 0s 489us/step - loss: 0.2072 - val_loss: 0.2801\n",
      "Epoch 226/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.2070 - val_loss: 0.2759\n",
      "Epoch 227/1000\n",
      "314/314 [==============================] - 0s 488us/step - loss: 0.2148 - val_loss: 0.2728\n",
      "Epoch 228/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.2072 - val_loss: 0.2763\n",
      "Epoch 229/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.2108 - val_loss: 0.2769\n",
      "Epoch 230/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.2074 - val_loss: 0.2751\n",
      "Epoch 231/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.2078 - val_loss: 0.2766\n",
      "Epoch 232/1000\n",
      "314/314 [==============================] - 0s 465us/step - loss: 0.2077 - val_loss: 0.2741\n",
      "Epoch 233/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.2047 - val_loss: 0.2740\n",
      "Epoch 234/1000\n",
      "314/314 [==============================] - 0s 513us/step - loss: 0.2096 - val_loss: 0.2795\n",
      "Epoch 235/1000\n",
      "314/314 [==============================] - 0s 520us/step - loss: 0.2018 - val_loss: 0.2794\n",
      "Epoch 236/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.2023 - val_loss: 0.2730\n",
      "Epoch 237/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.2033 - val_loss: 0.2747\n",
      "Epoch 238/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.2047 - val_loss: 0.2752\n",
      "Epoch 239/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.2122 - val_loss: 0.2813\n",
      "Epoch 240/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.2073 - val_loss: 0.2796\n",
      "Epoch 241/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.2109 - val_loss: 0.2709\n",
      "Epoch 242/1000\n",
      "314/314 [==============================] - 0s 478us/step - loss: 0.2081 - val_loss: 0.2741\n",
      "Epoch 243/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.2077 - val_loss: 0.2774\n",
      "Epoch 244/1000\n",
      "314/314 [==============================] - 0s 513us/step - loss: 0.2054 - val_loss: 0.2799\n",
      "Epoch 245/1000\n",
      "314/314 [==============================] - 0s 515us/step - loss: 0.2045 - val_loss: 0.2756\n",
      "Epoch 246/1000\n",
      "314/314 [==============================] - 0s 480us/step - loss: 0.2054 - val_loss: 0.2817\n",
      "Epoch 247/1000\n",
      "314/314 [==============================] - 0s 558us/step - loss: 0.2055 - val_loss: 0.2755\n",
      "Epoch 248/1000\n",
      "314/314 [==============================] - 0s 477us/step - loss: 0.2075 - val_loss: 0.2741\n",
      "Epoch 249/1000\n",
      "314/314 [==============================] - 0s 508us/step - loss: 0.2073 - val_loss: 0.2773\n",
      "Epoch 250/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.2079 - val_loss: 0.2778\n",
      "Epoch 251/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.2019 - val_loss: 0.2762\n",
      "Epoch 252/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2094 - val_loss: 0.2763\n",
      "Epoch 253/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2050 - val_loss: 0.2766\n",
      "Epoch 254/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.2043 - val_loss: 0.2764\n",
      "Epoch 255/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.2056 - val_loss: 0.2766\n",
      "Epoch 256/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2040 - val_loss: 0.2731\n",
      "Epoch 257/1000\n",
      "314/314 [==============================] - 0s 350us/step - loss: 0.2057 - val_loss: 0.2743\n",
      "Epoch 258/1000\n",
      "314/314 [==============================] - 0s 351us/step - loss: 0.2053 - val_loss: 0.2770\n",
      "Epoch 259/1000\n",
      "314/314 [==============================] - 0s 359us/step - loss: 0.2033 - val_loss: 0.2758\n",
      "Epoch 260/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2064 - val_loss: 0.2726\n",
      "Epoch 261/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2053 - val_loss: 0.2784\n",
      "Epoch 262/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.2100 - val_loss: 0.2789\n",
      "Epoch 263/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2073 - val_loss: 0.2790\n",
      "Epoch 264/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2092 - val_loss: 0.2751\n",
      "Epoch 265/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2050 - val_loss: 0.2714\n",
      "Epoch 266/1000\n",
      "314/314 [==============================] - 0s 358us/step - loss: 0.2017 - val_loss: 0.2797\n",
      "Epoch 267/1000\n",
      "314/314 [==============================] - 0s 356us/step - loss: 0.2067 - val_loss: 0.2816\n",
      "Epoch 268/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2054 - val_loss: 0.2832\n",
      "Epoch 269/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2066 - val_loss: 0.2791\n",
      "Epoch 270/1000\n",
      "314/314 [==============================] - 0s 356us/step - loss: 0.2018 - val_loss: 0.2793\n",
      "Epoch 271/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2031 - val_loss: 0.2785\n",
      "Epoch 272/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2064 - val_loss: 0.2815\n",
      "Epoch 273/1000\n",
      "314/314 [==============================] - 0s 361us/step - loss: 0.2043 - val_loss: 0.2779\n",
      "Epoch 274/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.2023 - val_loss: 0.2789\n",
      "Epoch 275/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2038 - val_loss: 0.2740\n",
      "Epoch 276/1000\n",
      "314/314 [==============================] - 0s 374us/step - loss: 0.2089 - val_loss: 0.2769\n",
      "Epoch 277/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2064 - val_loss: 0.2765\n",
      "Epoch 278/1000\n",
      "314/314 [==============================] - 0s 364us/step - loss: 0.2089 - val_loss: 0.2795\n",
      "Epoch 279/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2086 - val_loss: 0.2817\n",
      "Epoch 280/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2043 - val_loss: 0.2806\n",
      "Epoch 281/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2084 - val_loss: 0.2774\n",
      "Epoch 282/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2076 - val_loss: 0.2758\n",
      "Epoch 283/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2084 - val_loss: 0.2800\n",
      "Epoch 284/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2060 - val_loss: 0.2763\n",
      "Epoch 285/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2073 - val_loss: 0.2754\n",
      "Epoch 286/1000\n",
      "314/314 [==============================] - 0s 370us/step - loss: 0.2061 - val_loss: 0.2795\n",
      "Epoch 287/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.2059 - val_loss: 0.2811\n",
      "Epoch 288/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2099 - val_loss: 0.2736\n",
      "Epoch 289/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2041 - val_loss: 0.2763\n",
      "Epoch 290/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.2033 - val_loss: 0.2789\n",
      "Epoch 291/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.1990 - val_loss: 0.2790\n",
      "Epoch 292/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2043 - val_loss: 0.2808\n",
      "Epoch 293/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2030 - val_loss: 0.2767\n",
      "Epoch 294/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.2017 - val_loss: 0.2759\n",
      "Epoch 295/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2101 - val_loss: 0.2746\n",
      "Epoch 296/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.2072 - val_loss: 0.2745\n",
      "Epoch 297/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2075 - val_loss: 0.2782\n",
      "Epoch 298/1000\n",
      "314/314 [==============================] - 0s 446us/step - loss: 0.2074 - val_loss: 0.2772\n",
      "Epoch 299/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2012 - val_loss: 0.2779\n",
      "Epoch 300/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2033 - val_loss: 0.2774\n",
      "Epoch 301/1000\n",
      "314/314 [==============================] - 0s 374us/step - loss: 0.2042 - val_loss: 0.2772\n",
      "Epoch 302/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2022 - val_loss: 0.2817\n",
      "Epoch 303/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2021 - val_loss: 0.2775\n",
      "Epoch 304/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.2054 - val_loss: 0.2815\n",
      "Epoch 305/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2058 - val_loss: 0.2718\n",
      "Epoch 306/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2026 - val_loss: 0.2760\n",
      "Epoch 307/1000\n",
      "314/314 [==============================] - 0s 373us/step - loss: 0.2077 - val_loss: 0.2753\n",
      "Epoch 308/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2057 - val_loss: 0.2792\n",
      "Epoch 309/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 400us/step - loss: 0.2074 - val_loss: 0.2779\n",
      "Epoch 310/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.2034 - val_loss: 0.2766\n",
      "Epoch 311/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.2041 - val_loss: 0.2744\n",
      "Epoch 312/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2043 - val_loss: 0.2835\n",
      "Epoch 313/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.2059 - val_loss: 0.2777\n",
      "Epoch 314/1000\n",
      "314/314 [==============================] - 0s 387us/step - loss: 0.2109 - val_loss: 0.2744\n",
      "Epoch 315/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2038 - val_loss: 0.2757\n",
      "Epoch 316/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2080 - val_loss: 0.2716\n",
      "Epoch 317/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1994 - val_loss: 0.2756\n",
      "Epoch 318/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2022 - val_loss: 0.2790\n",
      "Epoch 319/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2050 - val_loss: 0.2746\n",
      "Epoch 320/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2045 - val_loss: 0.2753\n",
      "Epoch 321/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.2092 - val_loss: 0.2784\n",
      "Epoch 322/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2071 - val_loss: 0.2703\n",
      "Epoch 323/1000\n",
      "314/314 [==============================] - 0s 373us/step - loss: 0.2024 - val_loss: 0.2760\n",
      "Epoch 324/1000\n",
      "314/314 [==============================] - 0s 399us/step - loss: 0.2005 - val_loss: 0.2767\n",
      "Epoch 325/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2038 - val_loss: 0.2790\n",
      "Epoch 326/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2044 - val_loss: 0.2753\n",
      "Epoch 327/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2031 - val_loss: 0.2738\n",
      "Epoch 328/1000\n",
      "314/314 [==============================] - 0s 362us/step - loss: 0.2020 - val_loss: 0.2762\n",
      "Epoch 329/1000\n",
      "314/314 [==============================] - 0s 363us/step - loss: 0.2045 - val_loss: 0.2761\n",
      "Epoch 330/1000\n",
      "314/314 [==============================] - 0s 374us/step - loss: 0.2061 - val_loss: 0.2736\n",
      "Epoch 331/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.2021 - val_loss: 0.2752\n",
      "Epoch 332/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2046 - val_loss: 0.2765\n",
      "Epoch 333/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.2063 - val_loss: 0.2779\n",
      "Epoch 334/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2045 - val_loss: 0.2765\n",
      "Epoch 335/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.2048 - val_loss: 0.2792\n",
      "Epoch 336/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2055 - val_loss: 0.2756\n",
      "Epoch 337/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.2093 - val_loss: 0.2739\n",
      "Epoch 338/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.2043 - val_loss: 0.2797\n",
      "Epoch 339/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2051 - val_loss: 0.2757\n",
      "Epoch 340/1000\n",
      "314/314 [==============================] - 0s 364us/step - loss: 0.2094 - val_loss: 0.2766\n",
      "Epoch 341/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2064 - val_loss: 0.2744\n",
      "Epoch 342/1000\n",
      "314/314 [==============================] - 0s 345us/step - loss: 0.2058 - val_loss: 0.2782\n",
      "Epoch 343/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2010 - val_loss: 0.2724\n",
      "Epoch 344/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2022 - val_loss: 0.2736\n",
      "Epoch 345/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2048 - val_loss: 0.2805\n",
      "Epoch 346/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2078 - val_loss: 0.2809\n",
      "Epoch 347/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2024 - val_loss: 0.2781\n",
      "Epoch 348/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.2048 - val_loss: 0.2770\n",
      "Epoch 349/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2028 - val_loss: 0.2726\n",
      "Epoch 350/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2080 - val_loss: 0.2707\n",
      "Epoch 351/1000\n",
      "314/314 [==============================] - 0s 357us/step - loss: 0.2070 - val_loss: 0.2755\n",
      "Epoch 352/1000\n",
      "314/314 [==============================] - 0s 367us/step - loss: 0.2023 - val_loss: 0.2791\n",
      "Epoch 353/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2034 - val_loss: 0.2785\n",
      "Epoch 354/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2108 - val_loss: 0.2774\n",
      "Epoch 355/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2051 - val_loss: 0.2753\n",
      "Epoch 356/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.2017 - val_loss: 0.2767\n",
      "Epoch 357/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2038 - val_loss: 0.2779\n",
      "Epoch 358/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2053 - val_loss: 0.2768\n",
      "Epoch 359/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.2023 - val_loss: 0.2797\n",
      "Epoch 360/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2054 - val_loss: 0.2783\n",
      "Epoch 361/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2063 - val_loss: 0.2793\n",
      "Epoch 362/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2010 - val_loss: 0.2803\n",
      "Epoch 363/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2010 - val_loss: 0.2824\n",
      "Epoch 364/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2036 - val_loss: 0.2811\n",
      "Epoch 365/1000\n",
      "314/314 [==============================] - 0s 356us/step - loss: 0.2002 - val_loss: 0.2784\n",
      "Epoch 366/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2045 - val_loss: 0.2773\n",
      "Epoch 367/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2039 - val_loss: 0.2827\n",
      "Epoch 368/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.2074 - val_loss: 0.2806\n",
      "Epoch 369/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2068 - val_loss: 0.2786\n",
      "Epoch 370/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.2068 - val_loss: 0.2795\n",
      "Epoch 371/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2052 - val_loss: 0.2739\n",
      "Epoch 372/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2035 - val_loss: 0.2767\n",
      "Epoch 373/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2048 - val_loss: 0.2754\n",
      "Epoch 374/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2043 - val_loss: 0.2837\n",
      "Epoch 375/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2056 - val_loss: 0.2776\n",
      "Epoch 376/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2061 - val_loss: 0.2734\n",
      "Epoch 377/1000\n",
      "314/314 [==============================] - 0s 362us/step - loss: 0.2077 - val_loss: 0.2769\n",
      "Epoch 378/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2026 - val_loss: 0.2794\n",
      "Epoch 379/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1983 - val_loss: 0.2740\n",
      "Epoch 380/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2058 - val_loss: 0.2761\n",
      "Epoch 381/1000\n",
      "314/314 [==============================] - 0s 373us/step - loss: 0.2056 - val_loss: 0.2774\n",
      "Epoch 382/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.2061 - val_loss: 0.2734\n",
      "Epoch 383/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1992 - val_loss: 0.2764\n",
      "Epoch 384/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2019 - val_loss: 0.2751\n",
      "Epoch 385/1000\n",
      "314/314 [==============================] - 0s 363us/step - loss: 0.2032 - val_loss: 0.2747\n",
      "Epoch 386/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.2036 - val_loss: 0.2734\n",
      "Epoch 387/1000\n",
      "314/314 [==============================] - 0s 373us/step - loss: 0.2021 - val_loss: 0.2794\n",
      "Epoch 388/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.2003 - val_loss: 0.2836\n",
      "Epoch 389/1000\n",
      "314/314 [==============================] - 0s 364us/step - loss: 0.2009 - val_loss: 0.2804\n",
      "Epoch 390/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.2041 - val_loss: 0.2783\n",
      "Epoch 391/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.2013 - val_loss: 0.2709\n",
      "Epoch 392/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2012 - val_loss: 0.2767\n",
      "Epoch 393/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.1997 - val_loss: 0.2769\n",
      "Epoch 394/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.1988 - val_loss: 0.2779\n",
      "Epoch 395/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2018 - val_loss: 0.2769\n",
      "Epoch 396/1000\n",
      "314/314 [==============================] - 0s 374us/step - loss: 0.1989 - val_loss: 0.2761\n",
      "Epoch 397/1000\n",
      "314/314 [==============================] - 0s 370us/step - loss: 0.2072 - val_loss: 0.2781\n",
      "Epoch 398/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1988 - val_loss: 0.2760\n",
      "Epoch 399/1000\n",
      "314/314 [==============================] - 0s 367us/step - loss: 0.2011 - val_loss: 0.2741\n",
      "Epoch 400/1000\n",
      "314/314 [==============================] - 0s 356us/step - loss: 0.2014 - val_loss: 0.2752\n",
      "Epoch 401/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2006 - val_loss: 0.2755\n",
      "Epoch 402/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2013 - val_loss: 0.2785\n",
      "Epoch 403/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1996 - val_loss: 0.2754\n",
      "Epoch 404/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2053 - val_loss: 0.2750\n",
      "Epoch 405/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2060 - val_loss: 0.2751\n",
      "Epoch 406/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2040 - val_loss: 0.2760\n",
      "Epoch 407/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2065 - val_loss: 0.2751\n",
      "Epoch 408/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2067 - val_loss: 0.2739\n",
      "Epoch 409/1000\n",
      "314/314 [==============================] - 0s 373us/step - loss: 0.1996 - val_loss: 0.2747\n",
      "Epoch 410/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2001 - val_loss: 0.2770\n",
      "Epoch 411/1000\n",
      "314/314 [==============================] - 0s 358us/step - loss: 0.2086 - val_loss: 0.2761\n",
      "Epoch 412/1000\n",
      "314/314 [==============================] - 0s 359us/step - loss: 0.2016 - val_loss: 0.2795\n",
      "Epoch 413/1000\n",
      "314/314 [==============================] - 0s 361us/step - loss: 0.2039 - val_loss: 0.2762\n",
      "Epoch 414/1000\n",
      "314/314 [==============================] - 0s 365us/step - loss: 0.2066 - val_loss: 0.2776\n",
      "Epoch 415/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2006 - val_loss: 0.2776\n",
      "Epoch 416/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2018 - val_loss: 0.2724\n",
      "Epoch 417/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2083 - val_loss: 0.2713\n",
      "Epoch 418/1000\n",
      "314/314 [==============================] - 0s 373us/step - loss: 0.2053 - val_loss: 0.2714\n",
      "Epoch 419/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2030 - val_loss: 0.2775\n",
      "Epoch 420/1000\n",
      "314/314 [==============================] - 0s 399us/step - loss: 0.2011 - val_loss: 0.2747\n",
      "Epoch 421/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2044 - val_loss: 0.2787\n",
      "Epoch 422/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.2031 - val_loss: 0.2696\n",
      "Epoch 423/1000\n",
      "314/314 [==============================] - 0s 365us/step - loss: 0.1990 - val_loss: 0.2703\n",
      "Epoch 424/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.1987 - val_loss: 0.2785\n",
      "Epoch 425/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2006 - val_loss: 0.2761\n",
      "Epoch 426/1000\n",
      "314/314 [==============================] - 0s 396us/step - loss: 0.2036 - val_loss: 0.2769\n",
      "Epoch 427/1000\n",
      "314/314 [==============================] - 0s 380us/step - loss: 0.2040 - val_loss: 0.2783\n",
      "Epoch 428/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.1996 - val_loss: 0.2775\n",
      "Epoch 429/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.1973 - val_loss: 0.2744\n",
      "Epoch 430/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.2008 - val_loss: 0.2724\n",
      "Epoch 431/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1980 - val_loss: 0.2751\n",
      "Epoch 432/1000\n",
      "314/314 [==============================] - 0s 370us/step - loss: 0.2002 - val_loss: 0.2763\n",
      "Epoch 433/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.2042 - val_loss: 0.2796\n",
      "Epoch 434/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2005 - val_loss: 0.2698\n",
      "Epoch 435/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1985 - val_loss: 0.2755\n",
      "Epoch 436/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.1964 - val_loss: 0.2788\n",
      "Epoch 437/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.2000 - val_loss: 0.2812\n",
      "Epoch 438/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2018 - val_loss: 0.2776\n",
      "Epoch 439/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2048 - val_loss: 0.2772\n",
      "Epoch 440/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2018 - val_loss: 0.2748\n",
      "Epoch 441/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2020 - val_loss: 0.2793\n",
      "Epoch 442/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2033 - val_loss: 0.2749\n",
      "Epoch 443/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.1996 - val_loss: 0.2788\n",
      "Epoch 444/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.1987 - val_loss: 0.2795\n",
      "Epoch 445/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2009 - val_loss: 0.2774\n",
      "Epoch 446/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.1990 - val_loss: 0.2769\n",
      "Epoch 447/1000\n",
      "314/314 [==============================] - 0s 363us/step - loss: 0.1988 - val_loss: 0.2832\n",
      "Epoch 448/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2001 - val_loss: 0.2863\n",
      "Epoch 449/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.2004 - val_loss: 0.2816\n",
      "Epoch 450/1000\n",
      "314/314 [==============================] - 0s 359us/step - loss: 0.2011 - val_loss: 0.2734\n",
      "Epoch 451/1000\n",
      "314/314 [==============================] - 0s 363us/step - loss: 0.2029 - val_loss: 0.2731\n",
      "Epoch 452/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2020 - val_loss: 0.2730\n",
      "Epoch 453/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2033 - val_loss: 0.2737\n",
      "Epoch 454/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.1988 - val_loss: 0.2771\n",
      "Epoch 455/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.1983 - val_loss: 0.2775\n",
      "Epoch 456/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.1960 - val_loss: 0.2758\n",
      "Epoch 457/1000\n",
      "314/314 [==============================] - 0s 354us/step - loss: 0.1970 - val_loss: 0.2785\n",
      "Epoch 458/1000\n",
      "314/314 [==============================] - 0s 341us/step - loss: 0.1985 - val_loss: 0.2768\n",
      "Epoch 459/1000\n",
      "314/314 [==============================] - 0s 374us/step - loss: 0.2049 - val_loss: 0.2726\n",
      "Epoch 460/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2065 - val_loss: 0.2762\n",
      "Epoch 461/1000\n",
      "314/314 [==============================] - 0s 350us/step - loss: 0.2016 - val_loss: 0.2806\n",
      "Epoch 462/1000\n",
      "314/314 [==============================] - 0s 350us/step - loss: 0.1970 - val_loss: 0.2762\n",
      "Epoch 463/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 382us/step - loss: 0.1989 - val_loss: 0.2730\n",
      "Epoch 464/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2030 - val_loss: 0.2777\n",
      "Epoch 465/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1987 - val_loss: 0.2729\n",
      "Epoch 466/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2047 - val_loss: 0.2759\n",
      "Epoch 467/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2022 - val_loss: 0.2756\n",
      "Epoch 468/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2037 - val_loss: 0.2742\n",
      "Epoch 469/1000\n",
      "314/314 [==============================] - 0s 363us/step - loss: 0.1981 - val_loss: 0.2814\n",
      "Epoch 470/1000\n",
      "314/314 [==============================] - 0s 360us/step - loss: 0.1965 - val_loss: 0.2800\n",
      "Epoch 471/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2000 - val_loss: 0.2753\n",
      "Epoch 472/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2003 - val_loss: 0.2799\n",
      "Epoch 473/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.1983 - val_loss: 0.2753\n",
      "Epoch 474/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2065 - val_loss: 0.2727\n",
      "Epoch 475/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1960 - val_loss: 0.2715\n",
      "Epoch 476/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.1989 - val_loss: 0.2732\n",
      "Epoch 477/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2037 - val_loss: 0.2735\n",
      "Epoch 478/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2015 - val_loss: 0.2722\n",
      "Epoch 479/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2071 - val_loss: 0.2745\n",
      "Epoch 480/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2032 - val_loss: 0.2749\n",
      "Epoch 481/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.1962 - val_loss: 0.2777\n",
      "Epoch 482/1000\n",
      "314/314 [==============================] - 0s 357us/step - loss: 0.2021 - val_loss: 0.2772\n",
      "Epoch 483/1000\n",
      "314/314 [==============================] - 0s 356us/step - loss: 0.2013 - val_loss: 0.2761\n",
      "Epoch 484/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.2053 - val_loss: 0.2801\n",
      "Epoch 485/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1981 - val_loss: 0.2835\n",
      "Epoch 486/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.1992 - val_loss: 0.2781\n",
      "Epoch 487/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1995 - val_loss: 0.2738\n",
      "Epoch 488/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.1976 - val_loss: 0.2710\n",
      "Epoch 489/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2017 - val_loss: 0.2800\n",
      "Epoch 490/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.1978 - val_loss: 0.2806\n",
      "Epoch 491/1000\n",
      "314/314 [==============================] - 0s 372us/step - loss: 0.1991 - val_loss: 0.2756\n",
      "Epoch 492/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2042 - val_loss: 0.2754\n",
      "Epoch 493/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.2074 - val_loss: 0.2728\n",
      "Epoch 494/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.1950 - val_loss: 0.2783\n",
      "Epoch 495/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1995 - val_loss: 0.2789\n",
      "Epoch 496/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.1996 - val_loss: 0.2735\n",
      "Epoch 497/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.1991 - val_loss: 0.2758\n",
      "Epoch 498/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.2021 - val_loss: 0.2752\n",
      "Epoch 499/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.1988 - val_loss: 0.2764\n",
      "Epoch 500/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2010 - val_loss: 0.2747\n",
      "Epoch 501/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.2031 - val_loss: 0.2769\n",
      "Epoch 502/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2003 - val_loss: 0.2739\n",
      "Epoch 503/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.1987 - val_loss: 0.2735\n",
      "Epoch 504/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1937 - val_loss: 0.2756\n",
      "Epoch 505/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2021 - val_loss: 0.2766\n",
      "Epoch 506/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.2060 - val_loss: 0.2713\n",
      "Epoch 507/1000\n",
      "314/314 [==============================] - 0s 374us/step - loss: 0.1974 - val_loss: 0.2734\n",
      "Epoch 508/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1980 - val_loss: 0.2771\n",
      "Epoch 509/1000\n",
      "314/314 [==============================] - 0s 364us/step - loss: 0.1986 - val_loss: 0.2715\n",
      "Epoch 510/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.1912 - val_loss: 0.2717\n",
      "Epoch 511/1000\n",
      "314/314 [==============================] - 0s 365us/step - loss: 0.2003 - val_loss: 0.2768\n",
      "Epoch 512/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.1989 - val_loss: 0.2757\n",
      "Epoch 513/1000\n",
      "314/314 [==============================] - 0s 439us/step - loss: 0.1998 - val_loss: 0.2740\n",
      "Epoch 514/1000\n",
      "314/314 [==============================] - 0s 515us/step - loss: 0.2050 - val_loss: 0.2703\n",
      "Epoch 515/1000\n",
      "314/314 [==============================] - 0s 511us/step - loss: 0.2009 - val_loss: 0.2744\n",
      "Epoch 516/1000\n",
      "314/314 [==============================] - 0s 514us/step - loss: 0.2013 - val_loss: 0.2751\n",
      "Epoch 517/1000\n",
      "314/314 [==============================] - 0s 511us/step - loss: 0.2028 - val_loss: 0.2742\n",
      "Epoch 518/1000\n",
      "314/314 [==============================] - 0s 491us/step - loss: 0.1995 - val_loss: 0.2799\n",
      "Epoch 519/1000\n",
      "314/314 [==============================] - 0s 630us/step - loss: 0.1980 - val_loss: 0.2845\n",
      "Epoch 520/1000\n",
      "314/314 [==============================] - 0s 477us/step - loss: 0.1969 - val_loss: 0.2779\n",
      "Epoch 521/1000\n",
      "314/314 [==============================] - 0s 572us/step - loss: 0.1999 - val_loss: 0.2800\n",
      "Epoch 522/1000\n",
      "314/314 [==============================] - 0s 499us/step - loss: 0.2030 - val_loss: 0.2762\n",
      "Epoch 523/1000\n",
      "314/314 [==============================] - 0s 609us/step - loss: 0.2008 - val_loss: 0.2761\n",
      "Epoch 524/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1999 - val_loss: 0.2768\n",
      "Epoch 525/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.1991 - val_loss: 0.2774\n",
      "Epoch 526/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.1979 - val_loss: 0.2778\n",
      "Epoch 527/1000\n",
      "314/314 [==============================] - 0s 480us/step - loss: 0.2018 - val_loss: 0.2774\n",
      "Epoch 528/1000\n",
      "314/314 [==============================] - 0s 473us/step - loss: 0.2006 - val_loss: 0.2703\n",
      "Epoch 529/1000\n",
      "314/314 [==============================] - 0s 510us/step - loss: 0.1986 - val_loss: 0.2716\n",
      "Epoch 530/1000\n",
      "314/314 [==============================] - 0s 488us/step - loss: 0.1991 - val_loss: 0.2720\n",
      "Epoch 531/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.2026 - val_loss: 0.2750\n",
      "Epoch 532/1000\n",
      "314/314 [==============================] - 0s 495us/step - loss: 0.1988 - val_loss: 0.2712\n",
      "Epoch 533/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.2004 - val_loss: 0.2690\n",
      "Epoch 534/1000\n",
      "314/314 [==============================] - 0s 476us/step - loss: 0.1995 - val_loss: 0.2715\n",
      "Epoch 535/1000\n",
      "314/314 [==============================] - 0s 484us/step - loss: 0.1972 - val_loss: 0.2758\n",
      "Epoch 536/1000\n",
      "314/314 [==============================] - 0s 499us/step - loss: 0.2003 - val_loss: 0.2752\n",
      "Epoch 537/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.1976 - val_loss: 0.2688\n",
      "Epoch 538/1000\n",
      "314/314 [==============================] - 0s 436us/step - loss: 0.2004 - val_loss: 0.2719\n",
      "Epoch 539/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.1982 - val_loss: 0.2773\n",
      "Epoch 540/1000\n",
      "314/314 [==============================] - 0s 476us/step - loss: 0.2020 - val_loss: 0.2673\n",
      "Epoch 541/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2002 - val_loss: 0.2716\n",
      "Epoch 542/1000\n",
      "314/314 [==============================] - 0s 412us/step - loss: 0.1969 - val_loss: 0.2734\n",
      "Epoch 543/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.1971 - val_loss: 0.2711\n",
      "Epoch 544/1000\n",
      "314/314 [==============================] - 0s 363us/step - loss: 0.1962 - val_loss: 0.2726\n",
      "Epoch 545/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.2035 - val_loss: 0.2708\n",
      "Epoch 546/1000\n",
      "314/314 [==============================] - 0s 493us/step - loss: 0.1975 - val_loss: 0.2729\n",
      "Epoch 547/1000\n",
      "314/314 [==============================] - 0s 501us/step - loss: 0.1962 - val_loss: 0.2739\n",
      "Epoch 548/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2007 - val_loss: 0.2752\n",
      "Epoch 549/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.1984 - val_loss: 0.2748\n",
      "Epoch 550/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1984 - val_loss: 0.2728\n",
      "Epoch 551/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1961 - val_loss: 0.2728\n",
      "Epoch 552/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.1980 - val_loss: 0.2743\n",
      "Epoch 553/1000\n",
      "314/314 [==============================] - 0s 501us/step - loss: 0.2018 - val_loss: 0.2711\n",
      "Epoch 554/1000\n",
      "314/314 [==============================] - 0s 427us/step - loss: 0.1991 - val_loss: 0.2716\n",
      "Epoch 555/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.1945 - val_loss: 0.2759\n",
      "Epoch 556/1000\n",
      "314/314 [==============================] - 0s 445us/step - loss: 0.1982 - val_loss: 0.2746\n",
      "Epoch 557/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.1952 - val_loss: 0.2762\n",
      "Epoch 558/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.1977 - val_loss: 0.2755\n",
      "Epoch 559/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.2021 - val_loss: 0.2776\n",
      "Epoch 560/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.2013 - val_loss: 0.2766\n",
      "Epoch 561/1000\n",
      "314/314 [==============================] - 0s 502us/step - loss: 0.1991 - val_loss: 0.2751\n",
      "Epoch 562/1000\n",
      "314/314 [==============================] - 0s 473us/step - loss: 0.2059 - val_loss: 0.2701\n",
      "Epoch 563/1000\n",
      "314/314 [==============================] - 0s 508us/step - loss: 0.2038 - val_loss: 0.2773\n",
      "Epoch 564/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.2000 - val_loss: 0.2736\n",
      "Epoch 565/1000\n",
      "314/314 [==============================] - 0s 470us/step - loss: 0.1997 - val_loss: 0.2736\n",
      "Epoch 566/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.2007 - val_loss: 0.2779\n",
      "Epoch 567/1000\n",
      "314/314 [==============================] - 0s 482us/step - loss: 0.1993 - val_loss: 0.2717\n",
      "Epoch 568/1000\n",
      "314/314 [==============================] - 0s 463us/step - loss: 0.1964 - val_loss: 0.2725\n",
      "Epoch 569/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.1958 - val_loss: 0.2720\n",
      "Epoch 570/1000\n",
      "314/314 [==============================] - 0s 415us/step - loss: 0.1968 - val_loss: 0.2758\n",
      "Epoch 571/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.1990 - val_loss: 0.2724\n",
      "Epoch 572/1000\n",
      "314/314 [==============================] - 0s 413us/step - loss: 0.1938 - val_loss: 0.2790\n",
      "Epoch 573/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.1960 - val_loss: 0.2768\n",
      "Epoch 574/1000\n",
      "314/314 [==============================] - 0s 405us/step - loss: 0.1969 - val_loss: 0.2719\n",
      "Epoch 575/1000\n",
      "314/314 [==============================] - 0s 419us/step - loss: 0.1962 - val_loss: 0.2748\n",
      "Epoch 576/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.2037 - val_loss: 0.2718\n",
      "Epoch 577/1000\n",
      "314/314 [==============================] - 0s 438us/step - loss: 0.1988 - val_loss: 0.2710\n",
      "Epoch 578/1000\n",
      "314/314 [==============================] - 0s 412us/step - loss: 0.2001 - val_loss: 0.2825\n",
      "Epoch 579/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.2000 - val_loss: 0.2810\n",
      "Epoch 580/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.2003 - val_loss: 0.2815\n",
      "Epoch 581/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.1955 - val_loss: 0.2776\n",
      "Epoch 582/1000\n",
      "314/314 [==============================] - 0s 396us/step - loss: 0.1994 - val_loss: 0.2739\n",
      "Epoch 583/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1983 - val_loss: 0.2715\n",
      "Epoch 584/1000\n",
      "314/314 [==============================] - 0s 413us/step - loss: 0.1964 - val_loss: 0.2712\n",
      "Epoch 585/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2017 - val_loss: 0.2758\n",
      "Epoch 586/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.1928 - val_loss: 0.2773\n",
      "Epoch 587/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.2039 - val_loss: 0.2769\n",
      "Epoch 588/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.1991 - val_loss: 0.2801\n",
      "Epoch 589/1000\n",
      "314/314 [==============================] - 0s 437us/step - loss: 0.1966 - val_loss: 0.2743\n",
      "Epoch 590/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.1969 - val_loss: 0.2775\n",
      "Epoch 591/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2029 - val_loss: 0.2744\n",
      "Epoch 592/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.1965 - val_loss: 0.2813\n",
      "Epoch 593/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2032 - val_loss: 0.2799\n",
      "Epoch 594/1000\n",
      "314/314 [==============================] - 0s 427us/step - loss: 0.2042 - val_loss: 0.2695\n",
      "Epoch 595/1000\n",
      "314/314 [==============================] - 0s 410us/step - loss: 0.1989 - val_loss: 0.2711\n",
      "Epoch 596/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.1987 - val_loss: 0.2708\n",
      "Epoch 597/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.1982 - val_loss: 0.2762\n",
      "Epoch 598/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.1980 - val_loss: 0.2748\n",
      "Epoch 599/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.1981 - val_loss: 0.2768\n",
      "Epoch 600/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2024 - val_loss: 0.2749\n",
      "Epoch 601/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.1980 - val_loss: 0.2766\n",
      "Epoch 602/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.1952 - val_loss: 0.2763\n",
      "Epoch 603/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2007 - val_loss: 0.2708\n",
      "Epoch 604/1000\n",
      "314/314 [==============================] - 0s 421us/step - loss: 0.1996 - val_loss: 0.2719\n",
      "Epoch 605/1000\n",
      "314/314 [==============================] - 0s 409us/step - loss: 0.1995 - val_loss: 0.2786\n",
      "Epoch 606/1000\n",
      "314/314 [==============================] - 0s 408us/step - loss: 0.1972 - val_loss: 0.2789\n",
      "Epoch 607/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.1967 - val_loss: 0.2718\n",
      "Epoch 608/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.1979 - val_loss: 0.2727\n",
      "Epoch 609/1000\n",
      "314/314 [==============================] - 0s 406us/step - loss: 0.2006 - val_loss: 0.2791\n",
      "Epoch 610/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.1968 - val_loss: 0.2784\n",
      "Epoch 611/1000\n",
      "314/314 [==============================] - 0s 407us/step - loss: 0.1959 - val_loss: 0.2804\n",
      "Epoch 612/1000\n",
      "314/314 [==============================] - 0s 419us/step - loss: 0.1974 - val_loss: 0.2773\n",
      "Epoch 613/1000\n",
      "314/314 [==============================] - 0s 603us/step - loss: 0.1967 - val_loss: 0.2737\n",
      "Epoch 614/1000\n",
      "314/314 [==============================] - 0s 567us/step - loss: 0.1971 - val_loss: 0.2750\n",
      "Epoch 615/1000\n",
      "314/314 [==============================] - 0s 542us/step - loss: 0.2017 - val_loss: 0.2750\n",
      "Epoch 616/1000\n",
      "314/314 [==============================] - 0s 560us/step - loss: 0.1992 - val_loss: 0.2795\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 519us/step - loss: 0.2002 - val_loss: 0.2785\n",
      "Epoch 618/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.1997 - val_loss: 0.2769\n",
      "Epoch 619/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1928 - val_loss: 0.2723\n",
      "Epoch 620/1000\n",
      "314/314 [==============================] - 0s 397us/step - loss: 0.2012 - val_loss: 0.2743\n",
      "Epoch 621/1000\n",
      "314/314 [==============================] - 0s 415us/step - loss: 0.1971 - val_loss: 0.2798\n",
      "Epoch 622/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.2011 - val_loss: 0.2783\n",
      "Epoch 623/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.1999 - val_loss: 0.2776\n",
      "Epoch 624/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.2022 - val_loss: 0.2760\n",
      "Epoch 625/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.1974 - val_loss: 0.2744\n",
      "Epoch 626/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.1956 - val_loss: 0.2779\n",
      "Epoch 627/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.2011 - val_loss: 0.2849\n",
      "Epoch 628/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2041 - val_loss: 0.2771\n",
      "Epoch 629/1000\n",
      "314/314 [==============================] - 0s 365us/step - loss: 0.1924 - val_loss: 0.2795\n",
      "Epoch 630/1000\n",
      "314/314 [==============================] - 0s 369us/step - loss: 0.1990 - val_loss: 0.2789\n",
      "Epoch 631/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.1929 - val_loss: 0.2747\n",
      "Epoch 632/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.1974 - val_loss: 0.2731\n",
      "Epoch 633/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2006 - val_loss: 0.2696\n",
      "Epoch 634/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1977 - val_loss: 0.2743\n",
      "Epoch 635/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.1968 - val_loss: 0.2789\n",
      "Epoch 636/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.1943 - val_loss: 0.2768\n",
      "Epoch 637/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1962 - val_loss: 0.2742\n",
      "Epoch 638/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.1998 - val_loss: 0.2728\n",
      "Epoch 639/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.2000 - val_loss: 0.2790\n",
      "Epoch 640/1000\n",
      "314/314 [==============================] - 0s 394us/step - loss: 0.1971 - val_loss: 0.2741\n",
      "Epoch 641/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.2032 - val_loss: 0.2728\n",
      "Epoch 642/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.1992 - val_loss: 0.2721\n",
      "Epoch 643/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1999 - val_loss: 0.2755\n",
      "Epoch 644/1000\n",
      "314/314 [==============================] - 0s 394us/step - loss: 0.2042 - val_loss: 0.2724\n",
      "Epoch 645/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.1948 - val_loss: 0.2712\n",
      "Epoch 646/1000\n",
      "314/314 [==============================] - 0s 399us/step - loss: 0.1996 - val_loss: 0.2776\n",
      "Epoch 647/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.1998 - val_loss: 0.2795\n",
      "Epoch 648/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1962 - val_loss: 0.2775\n",
      "Epoch 649/1000\n",
      "314/314 [==============================] - 0s 381us/step - loss: 0.2025 - val_loss: 0.2744\n",
      "Epoch 650/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.1980 - val_loss: 0.2727\n",
      "Epoch 651/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1990 - val_loss: 0.2703\n",
      "Epoch 652/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.1971 - val_loss: 0.2723\n",
      "Epoch 653/1000\n",
      "314/314 [==============================] - 0s 393us/step - loss: 0.1966 - val_loss: 0.2757\n",
      "Epoch 654/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.1958 - val_loss: 0.2762\n",
      "Epoch 655/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.2017 - val_loss: 0.2763\n",
      "Epoch 656/1000\n",
      "314/314 [==============================] - 0s 396us/step - loss: 0.1941 - val_loss: 0.2721\n",
      "Epoch 657/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.1995 - val_loss: 0.2728\n",
      "Epoch 658/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1945 - val_loss: 0.2734\n",
      "Epoch 659/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.1960 - val_loss: 0.2767\n",
      "Epoch 660/1000\n",
      "314/314 [==============================] - 0s 425us/step - loss: 0.1964 - val_loss: 0.2719\n",
      "Epoch 661/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.1987 - val_loss: 0.2776\n",
      "Epoch 662/1000\n",
      "314/314 [==============================] - 0s 365us/step - loss: 0.1963 - val_loss: 0.2780\n",
      "Epoch 663/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.2027 - val_loss: 0.2713\n",
      "Epoch 664/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.2026 - val_loss: 0.2854\n",
      "Epoch 665/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.1982 - val_loss: 0.2692\n",
      "Epoch 666/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.2014 - val_loss: 0.2682\n",
      "Epoch 667/1000\n",
      "314/314 [==============================] - 0s 394us/step - loss: 0.1995 - val_loss: 0.2744\n",
      "Epoch 668/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.1945 - val_loss: 0.2767\n",
      "Epoch 669/1000\n",
      "314/314 [==============================] - 0s 409us/step - loss: 0.1986 - val_loss: 0.2721\n",
      "Epoch 670/1000\n",
      "314/314 [==============================] - 0s 370us/step - loss: 0.1966 - val_loss: 0.2735\n",
      "Epoch 671/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.2039 - val_loss: 0.2752\n",
      "Epoch 672/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.1953 - val_loss: 0.2767\n",
      "Epoch 673/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1914 - val_loss: 0.2682\n",
      "Epoch 674/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.1936 - val_loss: 0.2676\n",
      "Epoch 675/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.1990 - val_loss: 0.2730\n",
      "Epoch 676/1000\n",
      "314/314 [==============================] - 0s 415us/step - loss: 0.1956 - val_loss: 0.2709\n",
      "Epoch 677/1000\n",
      "314/314 [==============================] - 0s 378us/step - loss: 0.1929 - val_loss: 0.2727\n",
      "Epoch 678/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1959 - val_loss: 0.2732\n",
      "Epoch 679/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.1956 - val_loss: 0.2729\n",
      "Epoch 680/1000\n",
      "314/314 [==============================] - 0s 408us/step - loss: 0.1932 - val_loss: 0.2767\n",
      "Epoch 681/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.206 - 0s 371us/step - loss: 0.1965 - val_loss: 0.2795\n",
      "Epoch 682/1000\n",
      "314/314 [==============================] - 0s 421us/step - loss: 0.1972 - val_loss: 0.2732\n",
      "Epoch 683/1000\n",
      "314/314 [==============================] - 0s 450us/step - loss: 0.1983 - val_loss: 0.2688\n",
      "Epoch 684/1000\n",
      "314/314 [==============================] - 0s 424us/step - loss: 0.1982 - val_loss: 0.2688\n",
      "Epoch 685/1000\n",
      "314/314 [==============================] - 0s 481us/step - loss: 0.1963 - val_loss: 0.2732\n",
      "Epoch 686/1000\n",
      "314/314 [==============================] - 0s 413us/step - loss: 0.2040 - val_loss: 0.2745\n",
      "Epoch 687/1000\n",
      "314/314 [==============================] - 0s 425us/step - loss: 0.1961 - val_loss: 0.2775\n",
      "Epoch 688/1000\n",
      "314/314 [==============================] - 0s 429us/step - loss: 0.1975 - val_loss: 0.2727\n",
      "Epoch 689/1000\n",
      "314/314 [==============================] - 0s 442us/step - loss: 0.1999 - val_loss: 0.2777\n",
      "Epoch 690/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.1954 - val_loss: 0.2760\n",
      "Epoch 691/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.1949 - val_loss: 0.2722\n",
      "Epoch 692/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.2026 - val_loss: 0.2729\n",
      "Epoch 693/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.1939 - val_loss: 0.2766\n",
      "Epoch 694/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.2001 - val_loss: 0.2722\n",
      "Epoch 695/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1993 - val_loss: 0.2737\n",
      "Epoch 696/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.1984 - val_loss: 0.2772\n",
      "Epoch 697/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.2001 - val_loss: 0.2737\n",
      "Epoch 698/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.1951 - val_loss: 0.2730\n",
      "Epoch 699/1000\n",
      "314/314 [==============================] - 0s 403us/step - loss: 0.1926 - val_loss: 0.2695\n",
      "Epoch 700/1000\n",
      "314/314 [==============================] - 0s 400us/step - loss: 0.1971 - val_loss: 0.2697\n",
      "Epoch 701/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.1954 - val_loss: 0.2716\n",
      "Epoch 702/1000\n",
      "314/314 [==============================] - 0s 404us/step - loss: 0.1976 - val_loss: 0.2745\n",
      "Epoch 703/1000\n",
      "314/314 [==============================] - 0s 366us/step - loss: 0.1996 - val_loss: 0.2785\n",
      "Epoch 704/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1942 - val_loss: 0.2740\n",
      "Epoch 705/1000\n",
      "314/314 [==============================] - 0s 389us/step - loss: 0.1957 - val_loss: 0.2746\n",
      "Epoch 706/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.1961 - val_loss: 0.2755\n",
      "Epoch 707/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.1952 - val_loss: 0.2760\n",
      "Epoch 708/1000\n",
      "314/314 [==============================] - 0s 375us/step - loss: 0.1997 - val_loss: 0.2765\n",
      "Epoch 709/1000\n",
      "314/314 [==============================] - 0s 382us/step - loss: 0.1932 - val_loss: 0.2730\n",
      "Epoch 710/1000\n",
      "314/314 [==============================] - 0s 397us/step - loss: 0.1964 - val_loss: 0.2804\n",
      "Epoch 711/1000\n",
      "314/314 [==============================] - 0s 383us/step - loss: 0.1920 - val_loss: 0.2816\n",
      "Epoch 712/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1962 - val_loss: 0.2717\n",
      "Epoch 713/1000\n",
      "314/314 [==============================] - 0s 463us/step - loss: 0.1952 - val_loss: 0.2727\n",
      "Epoch 714/1000\n",
      "314/314 [==============================] - 0s 427us/step - loss: 0.1994 - val_loss: 0.2750\n",
      "Epoch 715/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1894 - val_loss: 0.2744\n",
      "Epoch 716/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.1953 - val_loss: 0.2775\n",
      "Epoch 717/1000\n",
      "314/314 [==============================] - 0s 370us/step - loss: 0.1960 - val_loss: 0.2717\n",
      "Epoch 718/1000\n",
      "314/314 [==============================] - 0s 368us/step - loss: 0.2035 - val_loss: 0.2782\n",
      "Epoch 719/1000\n",
      "314/314 [==============================] - 0s 392us/step - loss: 0.1952 - val_loss: 0.2783\n",
      "Epoch 720/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.1958 - val_loss: 0.2728\n",
      "Epoch 721/1000\n",
      "314/314 [==============================] - 0s 384us/step - loss: 0.1974 - val_loss: 0.2734\n",
      "Epoch 722/1000\n",
      "314/314 [==============================] - 0s 385us/step - loss: 0.2002 - val_loss: 0.2782\n",
      "Epoch 723/1000\n",
      "314/314 [==============================] - 0s 377us/step - loss: 0.1915 - val_loss: 0.2751\n",
      "Epoch 724/1000\n",
      "314/314 [==============================] - 0s 416us/step - loss: 0.1972 - val_loss: 0.2792\n",
      "Epoch 725/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.1901 - val_loss: 0.2757\n",
      "Epoch 726/1000\n",
      "314/314 [==============================] - 0s 416us/step - loss: 0.1979 - val_loss: 0.2705\n",
      "Epoch 727/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.1936 - val_loss: 0.2729\n",
      "Epoch 728/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1965 - val_loss: 0.2759\n",
      "Epoch 729/1000\n",
      "314/314 [==============================] - 0s 465us/step - loss: 0.1978 - val_loss: 0.2827\n",
      "Epoch 730/1000\n",
      "314/314 [==============================] - 0s 535us/step - loss: 0.1935 - val_loss: 0.2784\n",
      "Epoch 731/1000\n",
      "314/314 [==============================] - 0s 364us/step - loss: 0.1967 - val_loss: 0.2704\n",
      "Epoch 732/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.2025 - val_loss: 0.2683\n",
      "Epoch 733/1000\n",
      "314/314 [==============================] - 0s 409us/step - loss: 0.1941 - val_loss: 0.2717\n",
      "Epoch 734/1000\n",
      "314/314 [==============================] - 0s 390us/step - loss: 0.1927 - val_loss: 0.2746\n",
      "Epoch 735/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.1961 - val_loss: 0.2765\n",
      "Epoch 736/1000\n",
      "314/314 [==============================] - 0s 386us/step - loss: 0.1918 - val_loss: 0.2773\n",
      "Epoch 737/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.1956 - val_loss: 0.2808\n",
      "Epoch 738/1000\n",
      "314/314 [==============================] - 0s 446us/step - loss: 0.1929 - val_loss: 0.2794\n",
      "Epoch 739/1000\n",
      "314/314 [==============================] - 0s 423us/step - loss: 0.1998 - val_loss: 0.2760\n",
      "Epoch 740/1000\n",
      "314/314 [==============================] - 0s 379us/step - loss: 0.1923 - val_loss: 0.2738\n",
      "Epoch 741/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.1887 - val_loss: 0.2778\n",
      "Epoch 742/1000\n",
      "314/314 [==============================] - 0s 376us/step - loss: 0.1965 - val_loss: 0.2777\n",
      "Epoch 743/1000\n",
      "314/314 [==============================] - 0s 439us/step - loss: 0.1980 - val_loss: 0.2775\n",
      "Epoch 744/1000\n",
      "314/314 [==============================] - 0s 423us/step - loss: 0.1942 - val_loss: 0.2819\n",
      "Epoch 745/1000\n",
      "314/314 [==============================] - 0s 398us/step - loss: 0.1948 - val_loss: 0.2768\n",
      "Epoch 746/1000\n",
      "314/314 [==============================] - 0s 391us/step - loss: 0.1946 - val_loss: 0.2768\n",
      "Epoch 747/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1980 - val_loss: 0.2767\n",
      "Epoch 748/1000\n",
      "314/314 [==============================] - 0s 411us/step - loss: 0.1951 - val_loss: 0.2735\n",
      "Epoch 749/1000\n",
      "314/314 [==============================] - 0s 388us/step - loss: 0.1932 - val_loss: 0.2763\n",
      "Epoch 750/1000\n",
      "314/314 [==============================] - 0s 515us/step - loss: 0.1943 - val_loss: 0.2773\n",
      "Epoch 751/1000\n",
      "314/314 [==============================] - 0s 504us/step - loss: 0.1955 - val_loss: 0.2765\n",
      "Epoch 752/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.1995 - val_loss: 0.2767\n",
      "Epoch 753/1000\n",
      "314/314 [==============================] - 0s 399us/step - loss: 0.1951 - val_loss: 0.2758\n",
      "Epoch 754/1000\n",
      "314/314 [==============================] - 0s 402us/step - loss: 0.2010 - val_loss: 0.2714\n",
      "Epoch 755/1000\n",
      "314/314 [==============================] - 0s 371us/step - loss: 0.1979 - val_loss: 0.2751\n",
      "Epoch 756/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.2044 - val_loss: 0.2759\n",
      "Epoch 757/1000\n",
      "314/314 [==============================] - 0s 417us/step - loss: 0.1948 - val_loss: 0.2724\n",
      "Epoch 758/1000\n",
      "314/314 [==============================] - 0s 414us/step - loss: 0.1945 - val_loss: 0.2727\n",
      "Epoch 759/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.1935 - val_loss: 0.2810\n",
      "Epoch 760/1000\n",
      "314/314 [==============================] - 0s 495us/step - loss: 0.1929 - val_loss: 0.2728\n",
      "Epoch 761/1000\n",
      "314/314 [==============================] - 0s 590us/step - loss: 0.1991 - val_loss: 0.2731\n",
      "Epoch 762/1000\n",
      "314/314 [==============================] - 0s 420us/step - loss: 0.1932 - val_loss: 0.2766\n",
      "Epoch 763/1000\n",
      "314/314 [==============================] - 0s 558us/step - loss: 0.1965 - val_loss: 0.2816\n",
      "Epoch 764/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1977 - val_loss: 0.2756\n",
      "Epoch 765/1000\n",
      "314/314 [==============================] - 0s 570us/step - loss: 0.1995 - val_loss: 0.2700\n",
      "Epoch 766/1000\n",
      "314/314 [==============================] - 0s 691us/step - loss: 0.1943 - val_loss: 0.2720\n",
      "Epoch 767/1000\n",
      "314/314 [==============================] - 0s 764us/step - loss: 0.1902 - val_loss: 0.2705\n",
      "Epoch 768/1000\n",
      "314/314 [==============================] - 0s 766us/step - loss: 0.1945 - val_loss: 0.2726\n",
      "Epoch 769/1000\n",
      "314/314 [==============================] - 0s 694us/step - loss: 0.1983 - val_loss: 0.2747\n",
      "Epoch 770/1000\n",
      "314/314 [==============================] - 0s 713us/step - loss: 0.1996 - val_loss: 0.2706\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 0s 700us/step - loss: 0.1967 - val_loss: 0.2717\n",
      "Epoch 772/1000\n",
      "314/314 [==============================] - 0s 707us/step - loss: 0.1966 - val_loss: 0.2713\n",
      "Epoch 773/1000\n",
      "314/314 [==============================] - 0s 614us/step - loss: 0.1985 - val_loss: 0.2782\n",
      "Epoch 774/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1913 - val_loss: 0.2763\n",
      "Epoch 775/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1926 - val_loss: 0.2736\n",
      "Epoch 776/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.1945 - val_loss: 0.2751\n",
      "Epoch 777/1000\n",
      "314/314 [==============================] - 0s 493us/step - loss: 0.1963 - val_loss: 0.2752\n",
      "Epoch 778/1000\n",
      "314/314 [==============================] - 0s 484us/step - loss: 0.1914 - val_loss: 0.2723\n",
      "Epoch 779/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.1938 - val_loss: 0.2753\n",
      "Epoch 780/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.1975 - val_loss: 0.2755\n",
      "Epoch 781/1000\n",
      "314/314 [==============================] - 0s 474us/step - loss: 0.1898 - val_loss: 0.2686\n",
      "Epoch 782/1000\n",
      "314/314 [==============================] - 0s 446us/step - loss: 0.1989 - val_loss: 0.2741\n",
      "Epoch 783/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1909 - val_loss: 0.2807\n",
      "Epoch 784/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.1895 - val_loss: 0.2789\n",
      "Epoch 785/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.1939 - val_loss: 0.2677\n",
      "Epoch 786/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.1920 - val_loss: 0.2719\n",
      "Epoch 787/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.1945 - val_loss: 0.2729\n",
      "Epoch 788/1000\n",
      "314/314 [==============================] - 0s 455us/step - loss: 0.1906 - val_loss: 0.2713\n",
      "Epoch 789/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.1949 - val_loss: 0.2741\n",
      "Epoch 790/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.1930 - val_loss: 0.2758\n",
      "Epoch 791/1000\n",
      "314/314 [==============================] - 0s 442us/step - loss: 0.1908 - val_loss: 0.2726\n",
      "Epoch 792/1000\n",
      "314/314 [==============================] - 0s 436us/step - loss: 0.1934 - val_loss: 0.2717\n",
      "Epoch 793/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.1953 - val_loss: 0.2795\n",
      "Epoch 794/1000\n",
      "314/314 [==============================] - 0s 442us/step - loss: 0.1970 - val_loss: 0.2776\n",
      "Epoch 795/1000\n",
      "314/314 [==============================] - 0s 433us/step - loss: 0.1958 - val_loss: 0.2703\n",
      "Epoch 796/1000\n",
      "314/314 [==============================] - 0s 493us/step - loss: 0.1982 - val_loss: 0.2723\n",
      "Epoch 797/1000\n",
      "314/314 [==============================] - 0s 462us/step - loss: 0.1960 - val_loss: 0.2725\n",
      "Epoch 798/1000\n",
      "314/314 [==============================] - 0s 436us/step - loss: 0.1939 - val_loss: 0.2741\n",
      "Epoch 799/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.1913 - val_loss: 0.2786\n",
      "Epoch 800/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.1969 - val_loss: 0.2710\n",
      "Epoch 801/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.192 - 0s 458us/step - loss: 0.1950 - val_loss: 0.2739\n",
      "Epoch 802/1000\n",
      "314/314 [==============================] - 0s 557us/step - loss: 0.1907 - val_loss: 0.2702\n",
      "Epoch 803/1000\n",
      "314/314 [==============================] - 0s 847us/step - loss: 0.1918 - val_loss: 0.2739\n",
      "Epoch 804/1000\n",
      "314/314 [==============================] - ETA: 0s - loss: 0.201 - 0s 546us/step - loss: 0.1957 - val_loss: 0.2743\n",
      "Epoch 805/1000\n",
      "314/314 [==============================] - 0s 465us/step - loss: 0.1970 - val_loss: 0.2752\n",
      "Epoch 806/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.1909 - val_loss: 0.2706\n",
      "Epoch 807/1000\n",
      "314/314 [==============================] - 0s 732us/step - loss: 0.1950 - val_loss: 0.2754\n",
      "Epoch 808/1000\n",
      "314/314 [==============================] - 0s 547us/step - loss: 0.1922 - val_loss: 0.2779\n",
      "Epoch 809/1000\n",
      "314/314 [==============================] - 0s 538us/step - loss: 0.1930 - val_loss: 0.2762\n",
      "Epoch 810/1000\n",
      "314/314 [==============================] - 0s 586us/step - loss: 0.1885 - val_loss: 0.2776\n",
      "Epoch 811/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.2000 - val_loss: 0.2779\n",
      "Epoch 812/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1923 - val_loss: 0.2721\n",
      "Epoch 813/1000\n",
      "314/314 [==============================] - 0s 557us/step - loss: 0.1929 - val_loss: 0.2743\n",
      "Epoch 814/1000\n",
      "314/314 [==============================] - 0s 441us/step - loss: 0.1929 - val_loss: 0.2786\n",
      "Epoch 815/1000\n",
      "314/314 [==============================] - 0s 514us/step - loss: 0.1935 - val_loss: 0.2714\n",
      "Epoch 816/1000\n",
      "314/314 [==============================] - 0s 517us/step - loss: 0.1937 - val_loss: 0.2723\n",
      "Epoch 817/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1930 - val_loss: 0.2750\n",
      "Epoch 818/1000\n",
      "314/314 [==============================] - 0s 563us/step - loss: 0.1930 - val_loss: 0.2777\n",
      "Epoch 819/1000\n",
      "314/314 [==============================] - 0s 522us/step - loss: 0.1898 - val_loss: 0.2735\n",
      "Epoch 820/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1948 - val_loss: 0.2752\n",
      "Epoch 821/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1944 - val_loss: 0.2798\n",
      "Epoch 822/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.1933 - val_loss: 0.2754\n",
      "Epoch 823/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1979 - val_loss: 0.2734\n",
      "Epoch 824/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1913 - val_loss: 0.2733\n",
      "Epoch 825/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.1930 - val_loss: 0.2768\n",
      "Epoch 826/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1956 - val_loss: 0.2775\n",
      "Epoch 827/1000\n",
      "314/314 [==============================] - 0s 592us/step - loss: 0.1947 - val_loss: 0.2730\n",
      "Epoch 828/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.1936 - val_loss: 0.2732\n",
      "Epoch 829/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1939 - val_loss: 0.2750\n",
      "Epoch 830/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1927 - val_loss: 0.2723\n",
      "Epoch 831/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.2003 - val_loss: 0.2732\n",
      "Epoch 832/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1985 - val_loss: 0.2747\n",
      "Epoch 833/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.1926 - val_loss: 0.2741\n",
      "Epoch 834/1000\n",
      "314/314 [==============================] - 0s 503us/step - loss: 0.1955 - val_loss: 0.2722\n",
      "Epoch 835/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1892 - val_loss: 0.2729\n",
      "Epoch 836/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.1906 - val_loss: 0.2818\n",
      "Epoch 837/1000\n",
      "314/314 [==============================] - 0s 493us/step - loss: 0.1945 - val_loss: 0.2756\n",
      "Epoch 838/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.1939 - val_loss: 0.2717\n",
      "Epoch 839/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1916 - val_loss: 0.2753\n",
      "Epoch 840/1000\n",
      "314/314 [==============================] - 0s 538us/step - loss: 0.1937 - val_loss: 0.2739\n",
      "Epoch 841/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.1947 - val_loss: 0.2760\n",
      "Epoch 842/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.1981 - val_loss: 0.2805\n",
      "Epoch 843/1000\n",
      "314/314 [==============================] - 0s 538us/step - loss: 0.1947 - val_loss: 0.2778\n",
      "Epoch 844/1000\n",
      "314/314 [==============================] - 0s 573us/step - loss: 0.1958 - val_loss: 0.2759\n",
      "Epoch 845/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1981 - val_loss: 0.2741\n",
      "Epoch 846/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1922 - val_loss: 0.2761\n",
      "Epoch 847/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1928 - val_loss: 0.2717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.1907 - val_loss: 0.2798\n",
      "Epoch 849/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1997 - val_loss: 0.2777\n",
      "Epoch 850/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1988 - val_loss: 0.2757\n",
      "Epoch 851/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1947 - val_loss: 0.2782\n",
      "Epoch 852/1000\n",
      "314/314 [==============================] - 0s 569us/step - loss: 0.1935 - val_loss: 0.2740\n",
      "Epoch 853/1000\n",
      "314/314 [==============================] - 0s 554us/step - loss: 0.1903 - val_loss: 0.2789\n",
      "Epoch 854/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1914 - val_loss: 0.2740\n",
      "Epoch 855/1000\n",
      "314/314 [==============================] - 0s 535us/step - loss: 0.2001 - val_loss: 0.2759\n",
      "Epoch 856/1000\n",
      "314/314 [==============================] - 0s 510us/step - loss: 0.1908 - val_loss: 0.2735\n",
      "Epoch 857/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.1959 - val_loss: 0.2733\n",
      "Epoch 858/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1940 - val_loss: 0.2772\n",
      "Epoch 859/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.1956 - val_loss: 0.2779\n",
      "Epoch 860/1000\n",
      "314/314 [==============================] - 0s 592us/step - loss: 0.1961 - val_loss: 0.2704\n",
      "Epoch 861/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1846 - val_loss: 0.2733\n",
      "Epoch 862/1000\n",
      "314/314 [==============================] - 0s 567us/step - loss: 0.1994 - val_loss: 0.2763\n",
      "Epoch 863/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.1877 - val_loss: 0.2743\n",
      "Epoch 864/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1865 - val_loss: 0.2794\n",
      "Epoch 865/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.1963 - val_loss: 0.2762\n",
      "Epoch 866/1000\n",
      "314/314 [==============================] - 0s 563us/step - loss: 0.1952 - val_loss: 0.2714\n",
      "Epoch 867/1000\n",
      "314/314 [==============================] - 0s 560us/step - loss: 0.2003 - val_loss: 0.2726\n",
      "Epoch 868/1000\n",
      "314/314 [==============================] - 0s 592us/step - loss: 0.1926 - val_loss: 0.2704\n",
      "Epoch 869/1000\n",
      "314/314 [==============================] - 0s 570us/step - loss: 0.1887 - val_loss: 0.2692\n",
      "Epoch 870/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1895 - val_loss: 0.2660\n",
      "Epoch 871/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1966 - val_loss: 0.2691\n",
      "Epoch 872/1000\n",
      "314/314 [==============================] - 0s 586us/step - loss: 0.1883 - val_loss: 0.2779\n",
      "Epoch 873/1000\n",
      "314/314 [==============================] - 0s 484us/step - loss: 0.1957 - val_loss: 0.2769\n",
      "Epoch 874/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.1902 - val_loss: 0.2720\n",
      "Epoch 875/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1900 - val_loss: 0.2751\n",
      "Epoch 876/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.1919 - val_loss: 0.2769\n",
      "Epoch 877/1000\n",
      "314/314 [==============================] - 0s 571us/step - loss: 0.1864 - val_loss: 0.2763\n",
      "Epoch 878/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.1992 - val_loss: 0.2735\n",
      "Epoch 879/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1910 - val_loss: 0.2734\n",
      "Epoch 880/1000\n",
      "314/314 [==============================] - 0s 490us/step - loss: 0.1925 - val_loss: 0.2699\n",
      "Epoch 881/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.1991 - val_loss: 0.2732\n",
      "Epoch 882/1000\n",
      "314/314 [==============================] - 0s 532us/step - loss: 0.1967 - val_loss: 0.2719\n",
      "Epoch 883/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.1937 - val_loss: 0.2732\n",
      "Epoch 884/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1943 - val_loss: 0.2727\n",
      "Epoch 885/1000\n",
      "314/314 [==============================] - 0s 602us/step - loss: 0.1945 - val_loss: 0.2741\n",
      "Epoch 886/1000\n",
      "314/314 [==============================] - 0s 538us/step - loss: 0.1905 - val_loss: 0.2761\n",
      "Epoch 887/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1949 - val_loss: 0.2718\n",
      "Epoch 888/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1884 - val_loss: 0.2757\n",
      "Epoch 889/1000\n",
      "314/314 [==============================] - 0s 518us/step - loss: 0.1904 - val_loss: 0.2732\n",
      "Epoch 890/1000\n",
      "314/314 [==============================] - 0s 535us/step - loss: 0.1950 - val_loss: 0.2721\n",
      "Epoch 891/1000\n",
      "314/314 [==============================] - 0s 547us/step - loss: 0.1979 - val_loss: 0.2705\n",
      "Epoch 892/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1976 - val_loss: 0.2775\n",
      "Epoch 893/1000\n",
      "314/314 [==============================] - 0s 553us/step - loss: 0.1889 - val_loss: 0.2767\n",
      "Epoch 894/1000\n",
      "314/314 [==============================] - 0s 582us/step - loss: 0.1929 - val_loss: 0.2755\n",
      "Epoch 895/1000\n",
      "314/314 [==============================] - 0s 429us/step - loss: 0.1968 - val_loss: 0.2728\n",
      "Epoch 896/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1971 - val_loss: 0.2720\n",
      "Epoch 897/1000\n",
      "314/314 [==============================] - 0s 522us/step - loss: 0.1982 - val_loss: 0.2781\n",
      "Epoch 898/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1859 - val_loss: 0.2737\n",
      "Epoch 899/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1948 - val_loss: 0.2722\n",
      "Epoch 900/1000\n",
      "314/314 [==============================] - 0s 507us/step - loss: 0.1917 - val_loss: 0.2756\n",
      "Epoch 901/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1935 - val_loss: 0.2707\n",
      "Epoch 902/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.1973 - val_loss: 0.2724\n",
      "Epoch 903/1000\n",
      "314/314 [==============================] - 0s 613us/step - loss: 0.1908 - val_loss: 0.2834\n",
      "Epoch 904/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1979 - val_loss: 0.2809\n",
      "Epoch 905/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1950 - val_loss: 0.2715\n",
      "Epoch 906/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1945 - val_loss: 0.2735\n",
      "Epoch 907/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1940 - val_loss: 0.2767\n",
      "Epoch 908/1000\n",
      "314/314 [==============================] - 0s 521us/step - loss: 0.1877 - val_loss: 0.2728\n",
      "Epoch 909/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.1885 - val_loss: 0.2752\n",
      "Epoch 910/1000\n",
      "314/314 [==============================] - 0s 554us/step - loss: 0.1957 - val_loss: 0.2729\n",
      "Epoch 911/1000\n",
      "314/314 [==============================] - 0s 557us/step - loss: 0.1962 - val_loss: 0.2706\n",
      "Epoch 912/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1946 - val_loss: 0.2743\n",
      "Epoch 913/1000\n",
      "314/314 [==============================] - 0s 506us/step - loss: 0.1904 - val_loss: 0.2713\n",
      "Epoch 914/1000\n",
      "314/314 [==============================] - 0s 535us/step - loss: 0.1884 - val_loss: 0.2698\n",
      "Epoch 915/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1907 - val_loss: 0.2692\n",
      "Epoch 916/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1933 - val_loss: 0.2741\n",
      "Epoch 917/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.1964 - val_loss: 0.2765\n",
      "Epoch 918/1000\n",
      "314/314 [==============================] - 0s 487us/step - loss: 0.1901 - val_loss: 0.2734\n",
      "Epoch 919/1000\n",
      "314/314 [==============================] - 0s 563us/step - loss: 0.1891 - val_loss: 0.2721\n",
      "Epoch 920/1000\n",
      "314/314 [==============================] - 0s 538us/step - loss: 0.1908 - val_loss: 0.2753\n",
      "Epoch 921/1000\n",
      "314/314 [==============================] - 0s 547us/step - loss: 0.1948 - val_loss: 0.2725\n",
      "Epoch 922/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1932 - val_loss: 0.2753\n",
      "Epoch 923/1000\n",
      "314/314 [==============================] - 0s 501us/step - loss: 0.1846 - val_loss: 0.2780\n",
      "Epoch 924/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1924 - val_loss: 0.2778\n",
      "Epoch 925/1000\n",
      "314/314 [==============================] - 0s 524us/step - loss: 0.1888 - val_loss: 0.2730\n",
      "Epoch 926/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1897 - val_loss: 0.2697\n",
      "Epoch 927/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1885 - val_loss: 0.2703\n",
      "Epoch 928/1000\n",
      "314/314 [==============================] - 0s 586us/step - loss: 0.1930 - val_loss: 0.2795\n",
      "Epoch 929/1000\n",
      "314/314 [==============================] - 0s 471us/step - loss: 0.1917 - val_loss: 0.2768\n",
      "Epoch 930/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1903 - val_loss: 0.2761\n",
      "Epoch 931/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.1922 - val_loss: 0.2780\n",
      "Epoch 932/1000\n",
      "314/314 [==============================] - 0s 700us/step - loss: 0.1913 - val_loss: 0.2751\n",
      "Epoch 933/1000\n",
      "314/314 [==============================] - 0s 449us/step - loss: 0.1954 - val_loss: 0.2719\n",
      "Epoch 934/1000\n",
      "314/314 [==============================] - 0s 500us/step - loss: 0.1921 - val_loss: 0.2725\n",
      "Epoch 935/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1829 - val_loss: 0.2710\n",
      "Epoch 936/1000\n",
      "314/314 [==============================] - 0s 557us/step - loss: 0.1943 - val_loss: 0.2729\n",
      "Epoch 937/1000\n",
      "314/314 [==============================] - 0s 528us/step - loss: 0.1883 - val_loss: 0.2705\n",
      "Epoch 938/1000\n",
      "314/314 [==============================] - 0s 452us/step - loss: 0.1907 - val_loss: 0.2753\n",
      "Epoch 939/1000\n",
      "314/314 [==============================] - 0s 510us/step - loss: 0.1852 - val_loss: 0.2783\n",
      "Epoch 940/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1921 - val_loss: 0.2722\n",
      "Epoch 941/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1884 - val_loss: 0.2733\n",
      "Epoch 942/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1972 - val_loss: 0.2714\n",
      "Epoch 943/1000\n",
      "314/314 [==============================] - 0s 510us/step - loss: 0.1956 - val_loss: 0.2720\n",
      "Epoch 944/1000\n",
      "314/314 [==============================] - 0s 567us/step - loss: 0.1932 - val_loss: 0.2725\n",
      "Epoch 945/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1839 - val_loss: 0.2739\n",
      "Epoch 946/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1905 - val_loss: 0.2778\n",
      "Epoch 947/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1982 - val_loss: 0.2761\n",
      "Epoch 948/1000\n",
      "314/314 [==============================] - 0s 453us/step - loss: 0.1877 - val_loss: 0.2744\n",
      "Epoch 949/1000\n",
      "314/314 [==============================] - 0s 514us/step - loss: 0.1969 - val_loss: 0.2732\n",
      "Epoch 950/1000\n",
      "314/314 [==============================] - 0s 547us/step - loss: 0.1910 - val_loss: 0.2698\n",
      "Epoch 951/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1979 - val_loss: 0.2731\n",
      "Epoch 952/1000\n",
      "314/314 [==============================] - 0s 512us/step - loss: 0.1883 - val_loss: 0.2777\n",
      "Epoch 953/1000\n",
      "314/314 [==============================] - 0s 573us/step - loss: 0.1986 - val_loss: 0.2706\n",
      "Epoch 954/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1864 - val_loss: 0.2764\n",
      "Epoch 955/1000\n",
      "314/314 [==============================] - 0s 458us/step - loss: 0.1930 - val_loss: 0.2777\n",
      "Epoch 956/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.1925 - val_loss: 0.2744\n",
      "Epoch 957/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1932 - val_loss: 0.2771\n",
      "Epoch 958/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.1943 - val_loss: 0.2770\n",
      "Epoch 959/1000\n",
      "314/314 [==============================] - 0s 522us/step - loss: 0.1954 - val_loss: 0.2721\n",
      "Epoch 960/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1908 - val_loss: 0.2761\n",
      "Epoch 961/1000\n",
      "314/314 [==============================] - 0s 579us/step - loss: 0.1888 - val_loss: 0.2779\n",
      "Epoch 962/1000\n",
      "314/314 [==============================] - 0s 544us/step - loss: 0.1907 - val_loss: 0.2736\n",
      "Epoch 963/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1866 - val_loss: 0.2782\n",
      "Epoch 964/1000\n",
      "314/314 [==============================] - 0s 529us/step - loss: 0.1897 - val_loss: 0.2749\n",
      "Epoch 965/1000\n",
      "314/314 [==============================] - 0s 509us/step - loss: 0.1906 - val_loss: 0.2701\n",
      "Epoch 966/1000\n",
      "314/314 [==============================] - 0s 522us/step - loss: 0.1847 - val_loss: 0.2740\n",
      "Epoch 967/1000\n",
      "314/314 [==============================] - 0s 522us/step - loss: 0.1909 - val_loss: 0.2800\n",
      "Epoch 968/1000\n",
      "314/314 [==============================] - 0s 544us/step - loss: 0.1865 - val_loss: 0.2774\n",
      "Epoch 969/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1878 - val_loss: 0.2690\n",
      "Epoch 970/1000\n",
      "314/314 [==============================] - 0s 579us/step - loss: 0.1903 - val_loss: 0.2689\n",
      "Epoch 971/1000\n",
      "314/314 [==============================] - 0s 523us/step - loss: 0.1967 - val_loss: 0.2751\n",
      "Epoch 972/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1884 - val_loss: 0.2746\n",
      "Epoch 973/1000\n",
      "314/314 [==============================] - 0s 582us/step - loss: 0.1965 - val_loss: 0.2693\n",
      "Epoch 974/1000\n",
      "314/314 [==============================] - 0s 579us/step - loss: 0.1938 - val_loss: 0.2687\n",
      "Epoch 975/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1866 - val_loss: 0.2696\n",
      "Epoch 976/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1901 - val_loss: 0.2701\n",
      "Epoch 977/1000\n",
      "314/314 [==============================] - 0s 563us/step - loss: 0.1909 - val_loss: 0.2772\n",
      "Epoch 978/1000\n",
      "314/314 [==============================] - 0s 493us/step - loss: 0.1953 - val_loss: 0.2735\n",
      "Epoch 979/1000\n",
      "314/314 [==============================] - 0s 519us/step - loss: 0.1904 - val_loss: 0.2753\n",
      "Epoch 980/1000\n",
      "314/314 [==============================] - 0s 525us/step - loss: 0.1872 - val_loss: 0.2712\n",
      "Epoch 981/1000\n",
      "314/314 [==============================] - 0s 516us/step - loss: 0.1954 - val_loss: 0.2755\n",
      "Epoch 982/1000\n",
      "314/314 [==============================] - 0s 579us/step - loss: 0.1911 - val_loss: 0.2805\n",
      "Epoch 983/1000\n",
      "314/314 [==============================] - 0s 497us/step - loss: 0.1945 - val_loss: 0.2777\n",
      "Epoch 984/1000\n",
      "314/314 [==============================] - 0s 401us/step - loss: 0.1901 - val_loss: 0.2787\n",
      "Epoch 985/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.1953 - val_loss: 0.2750\n",
      "Epoch 986/1000\n",
      "314/314 [==============================] - 0s 468us/step - loss: 0.1897 - val_loss: 0.2713\n",
      "Epoch 987/1000\n",
      "314/314 [==============================] - 0s 621us/step - loss: 0.1890 - val_loss: 0.2782\n",
      "Epoch 988/1000\n",
      "314/314 [==============================] - 0s 483us/step - loss: 0.1915 - val_loss: 0.2763\n",
      "Epoch 989/1000\n",
      "314/314 [==============================] - 0s 495us/step - loss: 0.1923 - val_loss: 0.2726\n",
      "Epoch 990/1000\n",
      "314/314 [==============================] - 0s 504us/step - loss: 0.1905 - val_loss: 0.2738\n",
      "Epoch 991/1000\n",
      "314/314 [==============================] - 0s 484us/step - loss: 0.1893 - val_loss: 0.2703\n",
      "Epoch 992/1000\n",
      "314/314 [==============================] - 0s 818us/step - loss: 0.1845 - val_loss: 0.2725\n",
      "Epoch 993/1000\n",
      "314/314 [==============================] - 0s 589us/step - loss: 0.1982 - val_loss: 0.2749\n",
      "Epoch 994/1000\n",
      "314/314 [==============================] - 0s 491us/step - loss: 0.1934 - val_loss: 0.2686\n",
      "Epoch 995/1000\n",
      "314/314 [==============================] - 0s 541us/step - loss: 0.1866 - val_loss: 0.2656\n",
      "Epoch 996/1000\n",
      "314/314 [==============================] - 0s 534us/step - loss: 0.1890 - val_loss: 0.2694\n",
      "Epoch 997/1000\n",
      "314/314 [==============================] - 0s 489us/step - loss: 0.1899 - val_loss: 0.2700\n",
      "Epoch 998/1000\n",
      "314/314 [==============================] - 0s 395us/step - loss: 0.1879 - val_loss: 0.2713\n",
      "Epoch 999/1000\n",
      "314/314 [==============================] - 0s 352us/step - loss: 0.1897 - val_loss: 0.2734\n",
      "Epoch 1000/1000\n",
      "314/314 [==============================] - 0s 338us/step - loss: 0.1935 - val_loss: 0.2739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x286f998d978>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bidirectional\n",
    "regressor = Sequential()\n",
    "regressor.add(Bidirectional(LSTM(100, activation='relu'), input_shape=(1,X_train.shape[1])))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(1))\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "regressor.fit(x_train, y_train, epochs = 1000,  validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79        50\n",
      "           1       0.89      0.94      0.91       108\n",
      "\n",
      "    accuracy                           0.87       158\n",
      "   macro avg       0.86      0.84      0.85       158\n",
      "weighted avg       0.87      0.87      0.87       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = np.reshape(x_test, (x_test.shape[0],1,x_test.shape[1]))\n",
    "X_test.shape[0]\n",
    "\n",
    "# Classification report\n",
    "y_pred = regressor.predict_classes(X_test)\n",
    "y_pred.shape\n",
    "classification_report(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1\n",
      "Actual            \n",
      "0          37   13\n",
      "1           7  101\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.reshape(y_pred, (y_pred.shape[0]))\n",
    "y_pred.shape\n",
    "\n",
    "#confusion matrix:\n",
    "y_actual = pd.Series(y_test, name='Actual')\n",
    "y_predicted = pd.Series(y_pred, name='Predicted')\n",
    "confusion_matrix = pd.crosstab(y_actual, y_predicted)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
